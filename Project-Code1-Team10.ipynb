{"cells":[{"cell_type":"code","execution_count":4,"metadata":{"id":"x50Pj58IH6yc"},"outputs":[{"name":"stderr","output_type":"stream","text":["2022-12-06 11:40:27.129871: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"]}],"source":["import pandas as pd\n","import numpy as np\n","from datetime import datetime\n","from keras.models import Sequential\n","from keras.layers import Dense, Activation\n","from keras import optimizers\n","from keras.models import Sequential\n","from keras.layers import Dense, Activation\n","from keras import optimizers\n","from matplotlib import pyplot as plt\n","from collections import Counter\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score, f1_score\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.decomposition import PCA\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import GridSearchCV, KFold,StratifiedKFold, cross_val_score ,learning_curve ,ShuffleSplit,validation_curve,train_test_split\n","\n","from keras.models import Sequential\n","from keras.utils import np_utils\n","from keras.layers import Dense, Dropout, GaussianNoise, Conv1D\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.layers import LeakyReLU\n","from keras.callbacks import EarlyStopping\n","\n","from copy import deepcopy\n","from xgboost import XGBClassifier\n","import xgboost as xgb\n","from catboost import CatBoostClassifier"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"COC9qQZXH6yf"},"outputs":[],"source":["trainDF = pd.read_csv('ProjectTrainingData.csv')\n"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["testDF = pd.read_csv('ProjectTestData.csv')\n","testDF = testDF[['hour', 'C1', 'banner_pos', 'site_id', 'site_domain',\n","       'site_category', 'app_id', 'app_domain', 'app_category', 'device_id',\n","       'device_ip', 'device_model', 'device_type', 'device_conn_type', 'C14',\n","       'C15', 'C16', 'C17', 'C18', 'C19', 'C20', 'C21']]"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"tLEkywPiH6yg"},"outputs":[],"source":["pd.set_option(\"display.max_columns\",None)"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"YxVuCa-VH6yg","outputId":"1281d2a2-1b78-4ae4-f62a-b194eee7d778"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>click</th>\n","      <th>hour</th>\n","      <th>C1</th>\n","      <th>banner_pos</th>\n","      <th>site_id</th>\n","      <th>site_domain</th>\n","      <th>site_category</th>\n","      <th>app_id</th>\n","      <th>app_domain</th>\n","      <th>app_category</th>\n","      <th>device_id</th>\n","      <th>device_ip</th>\n","      <th>device_model</th>\n","      <th>device_type</th>\n","      <th>device_conn_type</th>\n","      <th>C14</th>\n","      <th>C15</th>\n","      <th>C16</th>\n","      <th>C17</th>\n","      <th>C18</th>\n","      <th>C19</th>\n","      <th>C20</th>\n","      <th>C21</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1.000009e+18</td>\n","      <td>0</td>\n","      <td>14102100</td>\n","      <td>1005</td>\n","      <td>0</td>\n","      <td>1fbe01fe</td>\n","      <td>f3845767</td>\n","      <td>28905ebd</td>\n","      <td>ecad2386</td>\n","      <td>7801e8d9</td>\n","      <td>07d7df22</td>\n","      <td>a99f214a</td>\n","      <td>ddd2926e</td>\n","      <td>44956a24</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>15706</td>\n","      <td>320</td>\n","      <td>50</td>\n","      <td>1722</td>\n","      <td>0</td>\n","      <td>35</td>\n","      <td>-1</td>\n","      <td>79</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1.000017e+19</td>\n","      <td>0</td>\n","      <td>14102100</td>\n","      <td>1005</td>\n","      <td>0</td>\n","      <td>1fbe01fe</td>\n","      <td>f3845767</td>\n","      <td>28905ebd</td>\n","      <td>ecad2386</td>\n","      <td>7801e8d9</td>\n","      <td>07d7df22</td>\n","      <td>a99f214a</td>\n","      <td>96809ac8</td>\n","      <td>711ee120</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>15704</td>\n","      <td>320</td>\n","      <td>50</td>\n","      <td>1722</td>\n","      <td>0</td>\n","      <td>35</td>\n","      <td>100084</td>\n","      <td>79</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1.000037e+19</td>\n","      <td>0</td>\n","      <td>14102100</td>\n","      <td>1005</td>\n","      <td>0</td>\n","      <td>1fbe01fe</td>\n","      <td>f3845767</td>\n","      <td>28905ebd</td>\n","      <td>ecad2386</td>\n","      <td>7801e8d9</td>\n","      <td>07d7df22</td>\n","      <td>a99f214a</td>\n","      <td>b3cf8def</td>\n","      <td>8a4875bd</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>15704</td>\n","      <td>320</td>\n","      <td>50</td>\n","      <td>1722</td>\n","      <td>0</td>\n","      <td>35</td>\n","      <td>100084</td>\n","      <td>79</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1.000064e+19</td>\n","      <td>0</td>\n","      <td>14102100</td>\n","      <td>1005</td>\n","      <td>0</td>\n","      <td>1fbe01fe</td>\n","      <td>f3845767</td>\n","      <td>28905ebd</td>\n","      <td>ecad2386</td>\n","      <td>7801e8d9</td>\n","      <td>07d7df22</td>\n","      <td>a99f214a</td>\n","      <td>e8275b8f</td>\n","      <td>6332421a</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>15706</td>\n","      <td>320</td>\n","      <td>50</td>\n","      <td>1722</td>\n","      <td>0</td>\n","      <td>35</td>\n","      <td>100084</td>\n","      <td>79</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1.000068e+19</td>\n","      <td>0</td>\n","      <td>14102100</td>\n","      <td>1005</td>\n","      <td>1</td>\n","      <td>fe8cc448</td>\n","      <td>9166c161</td>\n","      <td>0569f928</td>\n","      <td>ecad2386</td>\n","      <td>7801e8d9</td>\n","      <td>07d7df22</td>\n","      <td>a99f214a</td>\n","      <td>9644d0bf</td>\n","      <td>779d90c2</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>18993</td>\n","      <td>320</td>\n","      <td>50</td>\n","      <td>2161</td>\n","      <td>0</td>\n","      <td>35</td>\n","      <td>-1</td>\n","      <td>157</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["             id  click      hour    C1  banner_pos   site_id site_domain  \\\n","0  1.000009e+18      0  14102100  1005           0  1fbe01fe    f3845767   \n","1  1.000017e+19      0  14102100  1005           0  1fbe01fe    f3845767   \n","2  1.000037e+19      0  14102100  1005           0  1fbe01fe    f3845767   \n","3  1.000064e+19      0  14102100  1005           0  1fbe01fe    f3845767   \n","4  1.000068e+19      0  14102100  1005           1  fe8cc448    9166c161   \n","\n","  site_category    app_id app_domain app_category device_id device_ip  \\\n","0      28905ebd  ecad2386   7801e8d9     07d7df22  a99f214a  ddd2926e   \n","1      28905ebd  ecad2386   7801e8d9     07d7df22  a99f214a  96809ac8   \n","2      28905ebd  ecad2386   7801e8d9     07d7df22  a99f214a  b3cf8def   \n","3      28905ebd  ecad2386   7801e8d9     07d7df22  a99f214a  e8275b8f   \n","4      0569f928  ecad2386   7801e8d9     07d7df22  a99f214a  9644d0bf   \n","\n","  device_model  device_type  device_conn_type    C14  C15  C16   C17  C18  \\\n","0     44956a24            1                 2  15706  320   50  1722    0   \n","1     711ee120            1                 0  15704  320   50  1722    0   \n","2     8a4875bd            1                 0  15704  320   50  1722    0   \n","3     6332421a            1                 0  15706  320   50  1722    0   \n","4     779d90c2            1                 0  18993  320   50  2161    0   \n","\n","   C19     C20  C21  \n","0   35      -1   79  \n","1   35  100084   79  \n","2   35  100084   79  \n","3   35  100084   79  \n","4   35      -1  157  "]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["trainDF.head(5)"]},{"cell_type":"markdown","metadata":{"id":"schJc3p1H6yh"},"source":["# EDA and Data preparation"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"lcahfJtbH6yi","outputId":"cc4865de-b8bb-4e08-be22-3c71d9b0cc53"},"outputs":[{"data":{"text/plain":["(31991090, 24)"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["trainDF.shape"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"2C5-8Lr9H6yi","outputId":"b62884f3-aa6c-432e-e728-bff0c32f90da"},"outputs":[{"data":{"text/plain":["Index(['id', 'click', 'hour', 'C1', 'banner_pos', 'site_id', 'site_domain',\n","       'site_category', 'app_id', 'app_domain', 'app_category', 'device_id',\n","       'device_ip', 'device_model', 'device_type', 'device_conn_type', 'C14',\n","       'C15', 'C16', 'C17', 'C18', 'C19', 'C20', 'C21'],\n","      dtype='object')"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["trainDF.columns"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"hlHYQDheH6yj"},"outputs":[],"source":["def shaffle_data(df): \n","    df = df.sample(frac=1) # shuffle the data to split them to parts\n","    df = df.reset_index(drop=True)\n","    return df"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"NqLtCb8uH6yk"},"outputs":[],"source":["def split_data(df, part):\n","    data_dic ={}\n","\n","    # store splitted data in a dictionary\n","    for i in range(1,part+1):\n","        split_data = df.iloc[int(np.ceil(df.shape[0]/part)*(i-1)) : int(np.ceil(df.shape[0]/part)*i),:]\n","        data_dic['data'+str(i)] = split_data\n","\n","    return data_dic"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["def convert_hour(df): # convert the feature 'hour' to two numerical variables\n","    df['hour'] = pd.to_datetime(df['hour'], format = '%y%m%d%H') \n","    df['weekday'] = df['hour'].dt.weekday\n","    df['hour'] = df['hour'].dt.hour\n","    return df"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["def count_categories(df): # count the number of categories for each variables\n","    lst = []\n","    for i in df.columns:\n","        col = i\n","        num_cat = (df[i].nunique() )\n","        lst.append(num_cat)\n","    return lst"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["def get_X_y_test(part_of_data):\n","   traindf = 'data'+str(part_of_data)\n","   testdf = 'data'+str(part_of_data)\n","   \n","   df = all_tr[traindf]\n","\n","   X = df.loc[:,['hour', 'C1', 'banner_pos', 'site_id', 'site_domain',\n","       'site_category', 'app_id', 'app_domain', 'app_category', 'device_id',\n","       'device_ip', 'device_model', 'device_type', 'device_conn_type', 'C14',\n","       'C15', 'C16', 'C17', 'C18', 'C19', 'C20', 'C21', 'weekday']]\n","   y = df['click']\n","\n","   testDF = all_test[testdf]\n","\n","   return X, y,testDF"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["# convert the feature 'hour' to two numerical variables\n","train_cov = convert_hour(trainDF)\n","test_cov = convert_hour(testDF)\n","\n","# split the train data and test data to 10 pieces\n","random_seed =42\n","\n","part = 10 # split the data set to 10 parts\n","\n","shuffle_train = shaffle_data(train_cov)\n","all_tr = split_data(shuffle_train,part)\n","all_test = split_data(test_cov,part)\n"]},{"cell_type":"code","execution_count":55,"metadata":{},"outputs":[],"source":["# get the training dataset and test dataset\n","X, y,testDF = get_X_y_test(1)"]},{"cell_type":"code","execution_count":56,"metadata":{"id":"-S3qbQFbH6ym","outputId":"e314312b-ff86-4e5c-bc03-8d3211e1c6a3"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>feature</th>\n","      <th>train</th>\n","      <th>test</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>hour</td>\n","      <td>24</td>\n","      <td>24</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>C1</td>\n","      <td>7</td>\n","      <td>7</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>banner_pos</td>\n","      <td>7</td>\n","      <td>7</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>site_id</td>\n","      <td>3285</td>\n","      <td>2656</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>site_domain</td>\n","      <td>4019</td>\n","      <td>2902</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>site_category</td>\n","      <td>24</td>\n","      <td>22</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>app_id</td>\n","      <td>4535</td>\n","      <td>3366</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>app_domain</td>\n","      <td>286</td>\n","      <td>198</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>app_category</td>\n","      <td>30</td>\n","      <td>28</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>device_id</td>\n","      <td>417743</td>\n","      <td>161398</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>device_ip</td>\n","      <td>1347930</td>\n","      <td>660498</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>device_model</td>\n","      <td>6210</td>\n","      <td>5197</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>device_type</td>\n","      <td>5</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>device_conn_type</td>\n","      <td>4</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>C14</td>\n","      <td>2286</td>\n","      <td>2412</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>C15</td>\n","      <td>8</td>\n","      <td>8</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>C16</td>\n","      <td>9</td>\n","      <td>9</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>C17</td>\n","      <td>404</td>\n","      <td>462</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>C18</td>\n","      <td>4</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>C19</td>\n","      <td>65</td>\n","      <td>67</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>C20</td>\n","      <td>167</td>\n","      <td>163</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>C21</td>\n","      <td>55</td>\n","      <td>61</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>weekday</td>\n","      <td>7</td>\n","      <td>7</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["             feature    train    test\n","0               hour       24      24\n","1                 C1        7       7\n","2         banner_pos        7       7\n","3            site_id     3285    2656\n","4        site_domain     4019    2902\n","5      site_category       24      22\n","6             app_id     4535    3366\n","7         app_domain      286     198\n","8       app_category       30      28\n","9          device_id   417743  161398\n","10         device_ip  1347930  660498\n","11      device_model     6210    5197\n","12       device_type        5       4\n","13  device_conn_type        4       4\n","14               C14     2286    2412\n","15               C15        8       8\n","16               C16        9       9\n","17               C17      404     462\n","18               C18        4       4\n","19               C19       65      67\n","20               C20      167     163\n","21               C21       55      61\n","22           weekday        7       7"]},"execution_count":56,"metadata":{},"output_type":"execute_result"}],"source":["### according to the cardinality of different categorical variables, \n","### we can use our domain knowledge to determine to abandon some\n","### categories with high cardinality, and enable us to use one-hot\n","### encoding for the rest categorical features \n","### (no relationship between categories, so we use one-hot encoding)\n","freq_X = count_categories(X)\n","freq_test = count_categories(testDF)\n","data = [X.columns,freq_X,freq_test]\n","overview = pd.DataFrame(data).T\n","overview.columns = ['feature','train','test']\n","overview\n"]},{"cell_type":"code","execution_count":58,"metadata":{},"outputs":[{"data":{"text/plain":["array([<matplotlib.axes._subplots.AxesSubplot object at 0x7faa47a59700>],\n","      dtype=object)"]},"execution_count":58,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"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","text/plain":["<Figure size 864x576 with 3 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["fig, axes = plt.subplots(1, 3)\n","plt.rcParams[\"figure.figsize\"] = [12,8]\n","\n","\n","#target variable distribution\n","y.hist(ax = axes[0])\n","\n","### the distribution of numerical variables\n","X.hist(column='hour' ,ax= axes[1])\n","X.hist(column='weekday' ,ax= axes[2])\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["# Featur Processing"]},{"cell_type":"markdown","metadata":{"id":"p-m3U-Y2H6ym"},"source":["## Frequency Encoding and Feature Engineering"]},{"cell_type":"code","execution_count":59,"metadata":{"id":"UUOjxRtjH6ym"},"outputs":[],"source":["### according to the cardinality of different categorical variables, \n","### we can use frequency encoder to encode those categorical variables.\n","\n","### encoding for the rest categorical features by creating dummies\n","### (no relationship between categories, so we use one-hot encoding)\n","\n","def freq_encode(X,testDF,columns, threshold=10):\n","\n","    total_df = pd.concat([X,testDF])\n","\n","    for i in columns:\n","\n","        # if the categories for this variable is larger than threshold, use frequency encoding\n","        if total_df[i].nunique() > threshold:\n","            freq = (total_df.groupby(i).size())/len(total_df) # get the frequency\n","            total_df[i] = total_df[i].apply(lambda x: freq[x]) # apply frequency to the categorical variable colume\n","\n","        # if categories is less than threshold, create dummies for this variable\n","        if total_df[i].nunique() < threshold:\n","            temp_dummy = pd.get_dummies(total_df[i],drop_first=True) # create a temporary dataframe for the created dummies\n","            total_df.drop(i,axis=1, inplace=True) # drop the varibles from original dataset and append the dummies to it\n","            total_df = pd.concat([total_df,temp_dummy],axis=1)\n","            \n","    # split the dataset to training and test data\n","    X_final = total_df[0:X.shape[0]] \n","    testDF_final = total_df[X.shape[0]:]\n","\n","    return X_final, testDF_final\n"]},{"cell_type":"code","execution_count":60,"metadata":{},"outputs":[],"source":["def scale_num_var(df, col):\n","    # standardize the numerical variables with MinMaxScaler for train and test data\n","    scaler = MinMaxScaler()\n","    scaler.fit(df[col])\n","\n","    # transform the numerical column\n","    df[col] = scaler.transform(df[col])\n","    return df"]},{"cell_type":"code","execution_count":61,"metadata":{},"outputs":[],"source":["def drop_dup_colname(df):\n","    cols=pd.Series(df.columns)\n","\n","    for dup in cols[cols.duplicated()].unique(): \n","        cols[cols[cols == dup].index.values.tolist()] = [str(dup) + '.' + str(i) if i != 0 else dup for i in range(sum(cols == dup))]\n","\n","    # rename the columns with the cols list.\n","    df.columns=cols\n","\n","    return df"]},{"cell_type":"code","execution_count":62,"metadata":{"id":"VPbRCovMH6yn"},"outputs":[],"source":["X = X\n","\n","testDF = testDF\n","\n","columns = ['C1', 'banner_pos', 'site_id', 'site_domain', 'site_category',\n","    'app_id', 'app_domain', 'app_category', 'device_id', 'device_ip',\n","    'device_model', 'device_type', 'device_conn_type', 'C14', 'C15', 'C16',\n","    'C17', 'C18', 'C19', 'C20', 'C21']\n","\n","X_final, testDF_final = freq_encode(X,testDF,columns, threshold=10) # Encode categorical variables with high cardinality\n","\n","\n","# rename duplicated col names\n","X_final = drop_dup_colname(X_final) \n","X_final.columns = X_final.columns.astype(str)\n","testDF_final = drop_dup_colname(testDF_final)"]},{"cell_type":"markdown","metadata":{},"source":["# Core Modeling Function"]},{"cell_type":"code","execution_count":140,"metadata":{},"outputs":[],"source":["def nn_model(NEpochs, BatchSize, Optimizer, X, y,X_test):\n","    SpiralNN = Sequential()\n","\n","    SpiralNN.add(Dense(units=20,input_shape=(X.shape[1],),activation=\"relu\",use_bias=True))\n","    SpiralNN.add(Dense(units=15,activation=\"relu\",use_bias=True))\n","    SpiralNN.add(Dense(units=10,use_bias=True))\n","    SpiralNN.add(LeakyReLU(alpha=0.05))\n","    SpiralNN.add(Dense(units=5,activation=\"relu\",use_bias=True))\n","    SpiralNN.add(Dense(units=1,activation=\"sigmoid\",use_bias=True))\n","\n","    SpiralNN.compile(loss='binary_crossentropy', optimizer=Optimizer,metrics=['binary_crossentropy','accuracy'])\n","\n","    StopRule = EarlyStopping(monitor='binary_crossentropy',mode='min',verbose=0,patience=100,min_delta=0.0)\n","    FitHist = SpiralNN.fit(X,y,\\\n","                        epochs=NEpochs,batch_size=BatchSize,verbose=0, \\\n","                        callbacks=[StopRule])\n","    \n","    \n","    return SpiralNN"]},{"cell_type":"code","execution_count":64,"metadata":{},"outputs":[],"source":["def xgboost_bp(X,y):\n","    xgbc0 = xgb.XGBClassifier(objective='binary:logistic',\n","                          booster='gbtree',\n","                          eval_metric='logloss',\n","                          tree_method='hist',\n","                          grow_policy='lossguide',\n","                          use_label_encoder=False)\n","    default_params = {}\n","    gparams = xgbc0.get_params()\n","\n","    #default parameters have to be wrapped in lists - even single values - so GridSearchCV can take them as inputs\n","    for key in gparams.keys():\n","        gp = gparams[key]\n","        default_params[key] = [gp]\n","\n","    clf0 = GridSearchCV(estimator=xgbc0, scoring='neg_log_loss', param_grid=default_params, return_train_score=True, verbose=1, cv=3)\n","    clf0.fit(X, y.values.ravel())\n","\n","    params = deepcopy(default_params)\n","\n","    param_grid = {'max_depth': range (2, 10, 1),\n","                'n_estimators': range(60, 220, 40),\n","                'learning_rate': [1,0.1, 0.01 , 0.05],\n","                'tree_method':['hist'],\n","                'eval_metric':['logloss']}\n","\n","    gcvj = np.cumsum([len(x) for x in param_grid.values()])[-1]\n","\n","#iteration loop. Each selected parameter iterated separately\n","    for i,grid_key in enumerate(param_grid.keys()):\n","        \n","        #creating param_grid argument for GridSearchCV:\n","        #listing grid values of current iterable parameter and wrapping non-iterable parameter single values in list\n","        for param_key in params.keys():\n","            if param_key == grid_key:\n","                params[param_key] = param_grid[grid_key]\n","            else:\n","                #use best parameters of last iteration\n","                try:\n","                    param_value = [clf.best_params_[param_key]]\n","                    params[param_key] = param_value\n","                #use benchmark model parameters for first iteration\n","                except:\n","                    param_value = [clf0.best_params_[param_key]]\n","                    params[param_key] = param_value\n","        \n","        #classifier instance of current iteration\n","        xgbc = xgb.XGBClassifier(**default_params)\n","        \n","        #GridSearch instance of current iteration\n","        clf = GridSearchCV(estimator=xgbc, param_grid=params, scoring='neg_log_loss', return_train_score=True, verbose=0, cv=5)\n","        gs_clf = clf.fit(X, y.values.ravel())  \n","\n","        #best parameters\n","        bp = gs_clf.best_params_\n","\n","    return bp"]},{"cell_type":"markdown","metadata":{"id":"r_blbkCsH6yo"},"source":["# Modeling & Prediction"]},{"cell_type":"code","execution_count":65,"metadata":{},"outputs":[],"source":["X_train, X_test,y_train, y_test = train_test_split(X_final,y,test_size=0.3,random_state=42) # split this part of data to train and test data"]},{"cell_type":"markdown","metadata":{},"source":["################################### XGBoost #######################################"]},{"cell_type":"code","execution_count":66,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/Users/nigelsimida/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n","  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n","/Users/nigelsimida/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n","  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"]},{"name":"stdout","output_type":"stream","text":["Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"]},{"name":"stderr","output_type":"stream","text":["/Users/nigelsimida/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n","  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n","/Users/nigelsimida/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n","  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n","/Users/nigelsimida/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n","  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n","/Users/nigelsimida/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n","  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"]},{"data":{"text/html":["<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3,\n","             estimator=XGBClassifier(base_score=None, booster=&#x27;gbtree&#x27;,\n","                                     callbacks=None, colsample_bylevel=None,\n","                                     colsample_bynode=None,\n","                                     colsample_bytree=None,\n","                                     early_stopping_rounds=None,\n","                                     enable_categorical=False,\n","                                     eval_metric=&#x27;logloss&#x27;, feature_types=None,\n","                                     gamma=None, gpu_id=None,\n","                                     grow_policy=&#x27;lossguide&#x27;,\n","                                     importance_type=None,\n","                                     interaction_constraints=None,\n","                                     lea...\n","                         &#x27;max_cat_threshold&#x27;: [None],\n","                         &#x27;max_cat_to_onehot&#x27;: [None], &#x27;max_delta_step&#x27;: [None],\n","                         &#x27;max_depth&#x27;: [None], &#x27;max_leaves&#x27;: [None],\n","                         &#x27;min_child_weight&#x27;: [None], &#x27;missing&#x27;: [nan],\n","                         &#x27;monotone_constraints&#x27;: [None], &#x27;n_estimators&#x27;: [100],\n","                         &#x27;n_jobs&#x27;: [None], &#x27;num_parallel_tree&#x27;: [None],\n","                         &#x27;objective&#x27;: [&#x27;binary:logistic&#x27;], &#x27;predictor&#x27;: [None], ...},\n","             return_train_score=True, scoring=&#x27;neg_log_loss&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=3,\n","             estimator=XGBClassifier(base_score=None, booster=&#x27;gbtree&#x27;,\n","                                     callbacks=None, colsample_bylevel=None,\n","                                     colsample_bynode=None,\n","                                     colsample_bytree=None,\n","                                     early_stopping_rounds=None,\n","                                     enable_categorical=False,\n","                                     eval_metric=&#x27;logloss&#x27;, feature_types=None,\n","                                     gamma=None, gpu_id=None,\n","                                     grow_policy=&#x27;lossguide&#x27;,\n","                                     importance_type=None,\n","                                     interaction_constraints=None,\n","                                     lea...\n","                         &#x27;max_cat_threshold&#x27;: [None],\n","                         &#x27;max_cat_to_onehot&#x27;: [None], &#x27;max_delta_step&#x27;: [None],\n","                         &#x27;max_depth&#x27;: [None], &#x27;max_leaves&#x27;: [None],\n","                         &#x27;min_child_weight&#x27;: [None], &#x27;missing&#x27;: [nan],\n","                         &#x27;monotone_constraints&#x27;: [None], &#x27;n_estimators&#x27;: [100],\n","                         &#x27;n_jobs&#x27;: [None], &#x27;num_parallel_tree&#x27;: [None],\n","                         &#x27;objective&#x27;: [&#x27;binary:logistic&#x27;], &#x27;predictor&#x27;: [None], ...},\n","             return_train_score=True, scoring=&#x27;neg_log_loss&#x27;, verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=&#x27;gbtree&#x27;, callbacks=None,\n","              colsample_bylevel=None, colsample_bynode=None,\n","              colsample_bytree=None, early_stopping_rounds=None,\n","              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n","              feature_types=None, gamma=None, gpu_id=None,\n","              grow_policy=&#x27;lossguide&#x27;, importance_type=None,\n","              interaction_constraints=None, learning_rate=None, max_bin=None,\n","              max_cat_threshold=None, max_cat_to_onehot=None,\n","              max_delta_step=None, max_depth=None, max_leaves=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n","              predictor=None, random_state=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=&#x27;gbtree&#x27;, callbacks=None,\n","              colsample_bylevel=None, colsample_bynode=None,\n","              colsample_bytree=None, early_stopping_rounds=None,\n","              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n","              feature_types=None, gamma=None, gpu_id=None,\n","              grow_policy=&#x27;lossguide&#x27;, importance_type=None,\n","              interaction_constraints=None, learning_rate=None, max_bin=None,\n","              max_cat_threshold=None, max_cat_to_onehot=None,\n","              max_delta_step=None, max_depth=None, max_leaves=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n","              predictor=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"],"text/plain":["GridSearchCV(cv=3,\n","             estimator=XGBClassifier(base_score=None, booster='gbtree',\n","                                     callbacks=None, colsample_bylevel=None,\n","                                     colsample_bynode=None,\n","                                     colsample_bytree=None,\n","                                     early_stopping_rounds=None,\n","                                     enable_categorical=False,\n","                                     eval_metric='logloss', feature_types=None,\n","                                     gamma=None, gpu_id=None,\n","                                     grow_policy='lossguide',\n","                                     importance_type=None,\n","                                     interaction_constraints=None,\n","                                     lea...\n","                         'max_cat_threshold': [None],\n","                         'max_cat_to_onehot': [None], 'max_delta_step': [None],\n","                         'max_depth': [None], 'max_leaves': [None],\n","                         'min_child_weight': [None], 'missing': [nan],\n","                         'monotone_constraints': [None], 'n_estimators': [100],\n","                         'n_jobs': [None], 'num_parallel_tree': [None],\n","                         'objective': ['binary:logistic'], 'predictor': [None], ...},\n","             return_train_score=True, scoring='neg_log_loss', verbose=1)"]},"execution_count":66,"metadata":{},"output_type":"execute_result"}],"source":["xgbc0 = xgb.XGBClassifier(objective='binary:logistic',\n","                          booster='gbtree',\n","                          eval_metric='logloss',\n","                          tree_method='hist',\n","                          grow_policy='lossguide',\n","                          use_label_encoder=False)\n","default_params = {}\n","gparams = xgbc0.get_params()\n","\n","#default parameters have to be wrapped in lists - even single values - so GridSearchCV can take them as inputs\n","for key in gparams.keys():\n","    gp = gparams[key]\n","    default_params[key] = [gp]\n","\n","clf0 = GridSearchCV(estimator=xgbc0, scoring='neg_log_loss', param_grid=default_params, return_train_score=True, verbose=1, cv=3)\n","clf0.fit(X_train, y_train.values.ravel())"]},{"cell_type":"code","execution_count":74,"metadata":{},"outputs":[],"source":["pred_xg = clf0.predict_proba(X_test)[:,1]"]},{"cell_type":"code","execution_count":80,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0.3961504432088541\n"]}],"source":["print(log_loss(y_test,pred_xg))"]},{"cell_type":"markdown","metadata":{},"source":["################################### CATBoost #####################################"]},{"cell_type":"code","execution_count":88,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Learning rate set to 0.323282\n","0:\tlearn: 0.5378365\ttotal: 273ms\tremaining: 4m 32s\n","1:\tlearn: 0.4737658\ttotal: 438ms\tremaining: 3m 38s\n","2:\tlearn: 0.4471391\ttotal: 600ms\tremaining: 3m 19s\n","3:\tlearn: 0.4358405\ttotal: 744ms\tremaining: 3m 5s\n","4:\tlearn: 0.4292391\ttotal: 911ms\tremaining: 3m 1s\n","5:\tlearn: 0.4255785\ttotal: 1.07s\tremaining: 2m 57s\n","6:\tlearn: 0.4232537\ttotal: 1.24s\tremaining: 2m 55s\n","7:\tlearn: 0.4212973\ttotal: 1.39s\tremaining: 2m 52s\n","8:\tlearn: 0.4202859\ttotal: 1.52s\tremaining: 2m 47s\n","9:\tlearn: 0.4195170\ttotal: 1.68s\tremaining: 2m 46s\n","10:\tlearn: 0.4179801\ttotal: 1.84s\tremaining: 2m 45s\n","11:\tlearn: 0.4171362\ttotal: 2s\tremaining: 2m 44s\n","12:\tlearn: 0.4166975\ttotal: 2.15s\tremaining: 2m 42s\n","13:\tlearn: 0.4159771\ttotal: 2.29s\tremaining: 2m 41s\n","14:\tlearn: 0.4151771\ttotal: 2.43s\tremaining: 2m 39s\n","15:\tlearn: 0.4144868\ttotal: 2.59s\tremaining: 2m 39s\n","16:\tlearn: 0.4141522\ttotal: 2.78s\tremaining: 2m 40s\n","17:\tlearn: 0.4137457\ttotal: 2.96s\tremaining: 2m 41s\n","18:\tlearn: 0.4134142\ttotal: 3.14s\tremaining: 2m 42s\n","19:\tlearn: 0.4130194\ttotal: 3.27s\tremaining: 2m 40s\n","20:\tlearn: 0.4126654\ttotal: 3.42s\tremaining: 2m 39s\n","21:\tlearn: 0.4121994\ttotal: 3.57s\tremaining: 2m 38s\n","22:\tlearn: 0.4118984\ttotal: 3.71s\tremaining: 2m 37s\n","23:\tlearn: 0.4115001\ttotal: 3.85s\tremaining: 2m 36s\n","24:\tlearn: 0.4111960\ttotal: 4s\tremaining: 2m 36s\n","25:\tlearn: 0.4108142\ttotal: 4.16s\tremaining: 2m 35s\n","26:\tlearn: 0.4105715\ttotal: 4.3s\tremaining: 2m 35s\n","27:\tlearn: 0.4102060\ttotal: 4.45s\tremaining: 2m 34s\n","28:\tlearn: 0.4099210\ttotal: 4.6s\tremaining: 2m 33s\n","29:\tlearn: 0.4096300\ttotal: 4.72s\tremaining: 2m 32s\n","30:\tlearn: 0.4094228\ttotal: 4.87s\tremaining: 2m 32s\n","31:\tlearn: 0.4092354\ttotal: 5.01s\tremaining: 2m 31s\n","32:\tlearn: 0.4090352\ttotal: 5.15s\tremaining: 2m 30s\n","33:\tlearn: 0.4085958\ttotal: 5.31s\tremaining: 2m 30s\n","34:\tlearn: 0.4083487\ttotal: 5.46s\tremaining: 2m 30s\n","35:\tlearn: 0.4081363\ttotal: 5.61s\tremaining: 2m 30s\n","36:\tlearn: 0.4078112\ttotal: 5.75s\tremaining: 2m 29s\n","37:\tlearn: 0.4076223\ttotal: 5.89s\tremaining: 2m 29s\n","38:\tlearn: 0.4074164\ttotal: 6.03s\tremaining: 2m 28s\n","39:\tlearn: 0.4071735\ttotal: 6.17s\tremaining: 2m 28s\n","40:\tlearn: 0.4070602\ttotal: 6.32s\tremaining: 2m 27s\n","41:\tlearn: 0.4069061\ttotal: 6.47s\tremaining: 2m 27s\n","42:\tlearn: 0.4067287\ttotal: 6.63s\tremaining: 2m 27s\n","43:\tlearn: 0.4066450\ttotal: 6.78s\tremaining: 2m 27s\n","44:\tlearn: 0.4065751\ttotal: 6.93s\tremaining: 2m 27s\n","45:\tlearn: 0.4064611\ttotal: 7.06s\tremaining: 2m 26s\n","46:\tlearn: 0.4063379\ttotal: 7.21s\tremaining: 2m 26s\n","47:\tlearn: 0.4061814\ttotal: 7.35s\tremaining: 2m 25s\n","48:\tlearn: 0.4060020\ttotal: 7.48s\tremaining: 2m 25s\n","49:\tlearn: 0.4058444\ttotal: 7.62s\tremaining: 2m 24s\n","50:\tlearn: 0.4057321\ttotal: 7.77s\tremaining: 2m 24s\n","51:\tlearn: 0.4055892\ttotal: 7.89s\tremaining: 2m 23s\n","52:\tlearn: 0.4054756\ttotal: 8.05s\tremaining: 2m 23s\n","53:\tlearn: 0.4053232\ttotal: 8.23s\tremaining: 2m 24s\n","54:\tlearn: 0.4051789\ttotal: 8.43s\tremaining: 2m 24s\n","55:\tlearn: 0.4050784\ttotal: 8.63s\tremaining: 2m 25s\n","56:\tlearn: 0.4049515\ttotal: 8.79s\tremaining: 2m 25s\n","57:\tlearn: 0.4048022\ttotal: 8.94s\tremaining: 2m 25s\n","58:\tlearn: 0.4047079\ttotal: 9.06s\tremaining: 2m 24s\n","59:\tlearn: 0.4045624\ttotal: 9.21s\tremaining: 2m 24s\n","60:\tlearn: 0.4043420\ttotal: 9.37s\tremaining: 2m 24s\n","61:\tlearn: 0.4042132\ttotal: 9.5s\tremaining: 2m 23s\n","62:\tlearn: 0.4040441\ttotal: 9.64s\tremaining: 2m 23s\n","63:\tlearn: 0.4038519\ttotal: 9.8s\tremaining: 2m 23s\n","64:\tlearn: 0.4037768\ttotal: 9.97s\tremaining: 2m 23s\n","65:\tlearn: 0.4036843\ttotal: 10.1s\tremaining: 2m 23s\n","66:\tlearn: 0.4036162\ttotal: 10.3s\tremaining: 2m 23s\n","67:\tlearn: 0.4035531\ttotal: 10.4s\tremaining: 2m 22s\n","68:\tlearn: 0.4035153\ttotal: 10.6s\tremaining: 2m 22s\n","69:\tlearn: 0.4034560\ttotal: 10.7s\tremaining: 2m 22s\n","70:\tlearn: 0.4033580\ttotal: 10.9s\tremaining: 2m 22s\n","71:\tlearn: 0.4032894\ttotal: 11.1s\tremaining: 2m 22s\n","72:\tlearn: 0.4031526\ttotal: 11.3s\tremaining: 2m 22s\n","73:\tlearn: 0.4030852\ttotal: 11.4s\tremaining: 2m 22s\n","74:\tlearn: 0.4030203\ttotal: 11.5s\tremaining: 2m 22s\n","75:\tlearn: 0.4029589\ttotal: 11.7s\tremaining: 2m 22s\n","76:\tlearn: 0.4029313\ttotal: 11.8s\tremaining: 2m 21s\n","77:\tlearn: 0.4028622\ttotal: 12s\tremaining: 2m 21s\n","78:\tlearn: 0.4027354\ttotal: 12.1s\tremaining: 2m 21s\n","79:\tlearn: 0.4026617\ttotal: 12.3s\tremaining: 2m 21s\n","80:\tlearn: 0.4025957\ttotal: 12.4s\tremaining: 2m 20s\n","81:\tlearn: 0.4025124\ttotal: 12.6s\tremaining: 2m 20s\n","82:\tlearn: 0.4024549\ttotal: 12.7s\tremaining: 2m 20s\n","83:\tlearn: 0.4023885\ttotal: 12.9s\tremaining: 2m 20s\n","84:\tlearn: 0.4023041\ttotal: 13.1s\tremaining: 2m 20s\n","85:\tlearn: 0.4021270\ttotal: 13.2s\tremaining: 2m 20s\n","86:\tlearn: 0.4020669\ttotal: 13.3s\tremaining: 2m 19s\n","87:\tlearn: 0.4020050\ttotal: 13.5s\tremaining: 2m 19s\n","88:\tlearn: 0.4019305\ttotal: 13.6s\tremaining: 2m 19s\n","89:\tlearn: 0.4018897\ttotal: 13.8s\tremaining: 2m 19s\n","90:\tlearn: 0.4018429\ttotal: 14s\tremaining: 2m 19s\n","91:\tlearn: 0.4017175\ttotal: 14.1s\tremaining: 2m 19s\n","92:\tlearn: 0.4016631\ttotal: 14.3s\tremaining: 2m 19s\n","93:\tlearn: 0.4016010\ttotal: 14.4s\tremaining: 2m 19s\n","94:\tlearn: 0.4015075\ttotal: 14.6s\tremaining: 2m 19s\n","95:\tlearn: 0.4014570\ttotal: 14.7s\tremaining: 2m 18s\n","96:\tlearn: 0.4014122\ttotal: 14.9s\tremaining: 2m 18s\n","97:\tlearn: 0.4013745\ttotal: 15s\tremaining: 2m 18s\n","98:\tlearn: 0.4013212\ttotal: 15.2s\tremaining: 2m 18s\n","99:\tlearn: 0.4012589\ttotal: 15.4s\tremaining: 2m 18s\n","100:\tlearn: 0.4011833\ttotal: 15.6s\tremaining: 2m 18s\n","101:\tlearn: 0.4011491\ttotal: 15.7s\tremaining: 2m 18s\n","102:\tlearn: 0.4011153\ttotal: 15.9s\tremaining: 2m 18s\n","103:\tlearn: 0.4010338\ttotal: 16s\tremaining: 2m 17s\n","104:\tlearn: 0.4009991\ttotal: 16.1s\tremaining: 2m 17s\n","105:\tlearn: 0.4009746\ttotal: 16.3s\tremaining: 2m 17s\n","106:\tlearn: 0.4008594\ttotal: 16.5s\tremaining: 2m 17s\n","107:\tlearn: 0.4007872\ttotal: 16.7s\tremaining: 2m 17s\n","108:\tlearn: 0.4007493\ttotal: 16.9s\tremaining: 2m 17s\n","109:\tlearn: 0.4006908\ttotal: 17.1s\tremaining: 2m 17s\n","110:\tlearn: 0.4006640\ttotal: 17.2s\tremaining: 2m 17s\n","111:\tlearn: 0.4006129\ttotal: 17.4s\tremaining: 2m 17s\n","112:\tlearn: 0.4005630\ttotal: 17.5s\tremaining: 2m 17s\n","113:\tlearn: 0.4004726\ttotal: 17.7s\tremaining: 2m 17s\n","114:\tlearn: 0.4004040\ttotal: 17.9s\tremaining: 2m 17s\n","115:\tlearn: 0.4003524\ttotal: 18s\tremaining: 2m 17s\n","116:\tlearn: 0.4003129\ttotal: 18.2s\tremaining: 2m 16s\n","117:\tlearn: 0.4002208\ttotal: 18.3s\tremaining: 2m 16s\n","118:\tlearn: 0.4001665\ttotal: 18.5s\tremaining: 2m 16s\n","119:\tlearn: 0.3999943\ttotal: 18.6s\tremaining: 2m 16s\n","120:\tlearn: 0.3999402\ttotal: 18.8s\tremaining: 2m 16s\n","121:\tlearn: 0.3999125\ttotal: 19s\tremaining: 2m 16s\n","122:\tlearn: 0.3998935\ttotal: 19.1s\tremaining: 2m 16s\n","123:\tlearn: 0.3998615\ttotal: 19.3s\tremaining: 2m 16s\n","124:\tlearn: 0.3998199\ttotal: 19.4s\tremaining: 2m 15s\n","125:\tlearn: 0.3997801\ttotal: 19.6s\tremaining: 2m 15s\n","126:\tlearn: 0.3997325\ttotal: 19.7s\tremaining: 2m 15s\n","127:\tlearn: 0.3996722\ttotal: 19.9s\tremaining: 2m 15s\n","128:\tlearn: 0.3996221\ttotal: 20s\tremaining: 2m 14s\n","129:\tlearn: 0.3995755\ttotal: 20.2s\tremaining: 2m 14s\n","130:\tlearn: 0.3995394\ttotal: 20.3s\tremaining: 2m 14s\n","131:\tlearn: 0.3994810\ttotal: 20.4s\tremaining: 2m 14s\n","132:\tlearn: 0.3994202\ttotal: 20.6s\tremaining: 2m 14s\n","133:\tlearn: 0.3993900\ttotal: 20.7s\tremaining: 2m 13s\n","134:\tlearn: 0.3993449\ttotal: 20.9s\tremaining: 2m 13s\n","135:\tlearn: 0.3992742\ttotal: 21s\tremaining: 2m 13s\n","136:\tlearn: 0.3992287\ttotal: 21.2s\tremaining: 2m 13s\n","137:\tlearn: 0.3991892\ttotal: 21.3s\tremaining: 2m 13s\n","138:\tlearn: 0.3991227\ttotal: 21.5s\tremaining: 2m 12s\n","139:\tlearn: 0.3990847\ttotal: 21.7s\tremaining: 2m 13s\n","140:\tlearn: 0.3990237\ttotal: 21.8s\tremaining: 2m 13s\n","141:\tlearn: 0.3990012\ttotal: 22s\tremaining: 2m 13s\n","142:\tlearn: 0.3989612\ttotal: 22.2s\tremaining: 2m 12s\n","143:\tlearn: 0.3989157\ttotal: 22.3s\tremaining: 2m 12s\n","144:\tlearn: 0.3988528\ttotal: 22.5s\tremaining: 2m 12s\n","145:\tlearn: 0.3988150\ttotal: 22.7s\tremaining: 2m 12s\n","146:\tlearn: 0.3987810\ttotal: 22.8s\tremaining: 2m 12s\n","147:\tlearn: 0.3987558\ttotal: 23s\tremaining: 2m 12s\n","148:\tlearn: 0.3987099\ttotal: 23.1s\tremaining: 2m 12s\n","149:\tlearn: 0.3986765\ttotal: 23.3s\tremaining: 2m 11s\n","150:\tlearn: 0.3986548\ttotal: 23.4s\tremaining: 2m 11s\n","151:\tlearn: 0.3986369\ttotal: 23.6s\tremaining: 2m 11s\n","152:\tlearn: 0.3986093\ttotal: 23.8s\tremaining: 2m 11s\n","153:\tlearn: 0.3985665\ttotal: 23.9s\tremaining: 2m 11s\n","154:\tlearn: 0.3985205\ttotal: 24s\tremaining: 2m 10s\n","155:\tlearn: 0.3984673\ttotal: 24.1s\tremaining: 2m 10s\n","156:\tlearn: 0.3984072\ttotal: 24.3s\tremaining: 2m 10s\n","157:\tlearn: 0.3983863\ttotal: 24.4s\tremaining: 2m 10s\n","158:\tlearn: 0.3983623\ttotal: 24.6s\tremaining: 2m 10s\n","159:\tlearn: 0.3983337\ttotal: 24.7s\tremaining: 2m 9s\n","160:\tlearn: 0.3983167\ttotal: 24.9s\tremaining: 2m 9s\n","161:\tlearn: 0.3982680\ttotal: 25s\tremaining: 2m 9s\n","162:\tlearn: 0.3982406\ttotal: 25.2s\tremaining: 2m 9s\n","163:\tlearn: 0.3982017\ttotal: 25.3s\tremaining: 2m 8s\n","164:\tlearn: 0.3981692\ttotal: 25.4s\tremaining: 2m 8s\n","165:\tlearn: 0.3981557\ttotal: 25.6s\tremaining: 2m 8s\n","166:\tlearn: 0.3981186\ttotal: 25.7s\tremaining: 2m 8s\n","167:\tlearn: 0.3980727\ttotal: 25.9s\tremaining: 2m 8s\n","168:\tlearn: 0.3980148\ttotal: 26s\tremaining: 2m 7s\n","169:\tlearn: 0.3979905\ttotal: 26.1s\tremaining: 2m 7s\n","170:\tlearn: 0.3979765\ttotal: 26.3s\tremaining: 2m 7s\n","171:\tlearn: 0.3978832\ttotal: 26.5s\tremaining: 2m 7s\n","172:\tlearn: 0.3978398\ttotal: 26.6s\tremaining: 2m 7s\n","173:\tlearn: 0.3978011\ttotal: 26.8s\tremaining: 2m 7s\n","174:\tlearn: 0.3977281\ttotal: 27s\tremaining: 2m 7s\n","175:\tlearn: 0.3976949\ttotal: 27.1s\tremaining: 2m 6s\n","176:\tlearn: 0.3976694\ttotal: 27.3s\tremaining: 2m 6s\n","177:\tlearn: 0.3976464\ttotal: 27.4s\tremaining: 2m 6s\n","178:\tlearn: 0.3976258\ttotal: 27.5s\tremaining: 2m 6s\n","179:\tlearn: 0.3975804\ttotal: 27.7s\tremaining: 2m 6s\n","180:\tlearn: 0.3975552\ttotal: 27.8s\tremaining: 2m 5s\n","181:\tlearn: 0.3975298\ttotal: 28s\tremaining: 2m 5s\n","182:\tlearn: 0.3975143\ttotal: 28.1s\tremaining: 2m 5s\n","183:\tlearn: 0.3974916\ttotal: 28.3s\tremaining: 2m 5s\n","184:\tlearn: 0.3974418\ttotal: 28.4s\tremaining: 2m 5s\n","185:\tlearn: 0.3974109\ttotal: 28.5s\tremaining: 2m 4s\n","186:\tlearn: 0.3973625\ttotal: 28.7s\tremaining: 2m 4s\n","187:\tlearn: 0.3973170\ttotal: 28.8s\tremaining: 2m 4s\n","188:\tlearn: 0.3972668\ttotal: 29s\tremaining: 2m 4s\n","189:\tlearn: 0.3972452\ttotal: 29.1s\tremaining: 2m 4s\n","190:\tlearn: 0.3972179\ttotal: 29.3s\tremaining: 2m 3s\n","191:\tlearn: 0.3971980\ttotal: 29.4s\tremaining: 2m 3s\n","192:\tlearn: 0.3971800\ttotal: 29.5s\tremaining: 2m 3s\n","193:\tlearn: 0.3971551\ttotal: 29.7s\tremaining: 2m 3s\n","194:\tlearn: 0.3971325\ttotal: 29.8s\tremaining: 2m 3s\n","195:\tlearn: 0.3971108\ttotal: 30s\tremaining: 2m 3s\n","196:\tlearn: 0.3970660\ttotal: 30.2s\tremaining: 2m 2s\n","197:\tlearn: 0.3970462\ttotal: 30.3s\tremaining: 2m 2s\n","198:\tlearn: 0.3970145\ttotal: 30.4s\tremaining: 2m 2s\n","199:\tlearn: 0.3969817\ttotal: 30.6s\tremaining: 2m 2s\n","200:\tlearn: 0.3969505\ttotal: 30.7s\tremaining: 2m 1s\n","201:\tlearn: 0.3969332\ttotal: 30.8s\tremaining: 2m 1s\n","202:\tlearn: 0.3969102\ttotal: 31s\tremaining: 2m 1s\n","203:\tlearn: 0.3968945\ttotal: 31.1s\tremaining: 2m 1s\n","204:\tlearn: 0.3968692\ttotal: 31.2s\tremaining: 2m 1s\n","205:\tlearn: 0.3968472\ttotal: 31.4s\tremaining: 2m\n","206:\tlearn: 0.3968124\ttotal: 31.5s\tremaining: 2m\n","207:\tlearn: 0.3967911\ttotal: 31.7s\tremaining: 2m\n","208:\tlearn: 0.3967706\ttotal: 31.8s\tremaining: 2m\n","209:\tlearn: 0.3967477\ttotal: 32s\tremaining: 2m\n","210:\tlearn: 0.3967299\ttotal: 32.1s\tremaining: 2m\n","211:\tlearn: 0.3967065\ttotal: 32.3s\tremaining: 2m\n","212:\tlearn: 0.3967000\ttotal: 32.4s\tremaining: 1m 59s\n","213:\tlearn: 0.3966676\ttotal: 32.6s\tremaining: 1m 59s\n","214:\tlearn: 0.3966367\ttotal: 32.7s\tremaining: 1m 59s\n","215:\tlearn: 0.3966087\ttotal: 32.9s\tremaining: 1m 59s\n","216:\tlearn: 0.3965818\ttotal: 33s\tremaining: 1m 59s\n","217:\tlearn: 0.3965693\ttotal: 33.2s\tremaining: 1m 59s\n","218:\tlearn: 0.3965482\ttotal: 33.3s\tremaining: 1m 58s\n","219:\tlearn: 0.3965154\ttotal: 33.5s\tremaining: 1m 58s\n","220:\tlearn: 0.3964526\ttotal: 33.6s\tremaining: 1m 58s\n","221:\tlearn: 0.3964262\ttotal: 33.8s\tremaining: 1m 58s\n","222:\tlearn: 0.3964074\ttotal: 33.9s\tremaining: 1m 58s\n","223:\tlearn: 0.3963836\ttotal: 34.1s\tremaining: 1m 58s\n","224:\tlearn: 0.3963637\ttotal: 34.2s\tremaining: 1m 57s\n","225:\tlearn: 0.3963163\ttotal: 34.4s\tremaining: 1m 57s\n","226:\tlearn: 0.3962641\ttotal: 34.5s\tremaining: 1m 57s\n","227:\tlearn: 0.3962527\ttotal: 34.7s\tremaining: 1m 57s\n","228:\tlearn: 0.3962342\ttotal: 34.8s\tremaining: 1m 57s\n","229:\tlearn: 0.3962194\ttotal: 35s\tremaining: 1m 57s\n","230:\tlearn: 0.3962028\ttotal: 35.1s\tremaining: 1m 56s\n","231:\tlearn: 0.3961603\ttotal: 35.3s\tremaining: 1m 56s\n","232:\tlearn: 0.3961364\ttotal: 35.4s\tremaining: 1m 56s\n","233:\tlearn: 0.3961128\ttotal: 35.6s\tremaining: 1m 56s\n","234:\tlearn: 0.3961006\ttotal: 35.7s\tremaining: 1m 56s\n","235:\tlearn: 0.3960834\ttotal: 35.9s\tremaining: 1m 56s\n","236:\tlearn: 0.3960658\ttotal: 36.1s\tremaining: 1m 56s\n","237:\tlearn: 0.3960374\ttotal: 36.2s\tremaining: 1m 56s\n","238:\tlearn: 0.3960049\ttotal: 36.4s\tremaining: 1m 55s\n","239:\tlearn: 0.3959745\ttotal: 36.6s\tremaining: 1m 55s\n","240:\tlearn: 0.3959573\ttotal: 36.7s\tremaining: 1m 55s\n","241:\tlearn: 0.3959398\ttotal: 36.9s\tremaining: 1m 55s\n","242:\tlearn: 0.3959189\ttotal: 37s\tremaining: 1m 55s\n","243:\tlearn: 0.3959086\ttotal: 37.1s\tremaining: 1m 55s\n","244:\tlearn: 0.3958914\ttotal: 37.3s\tremaining: 1m 54s\n","245:\tlearn: 0.3958754\ttotal: 37.4s\tremaining: 1m 54s\n","246:\tlearn: 0.3958547\ttotal: 37.6s\tremaining: 1m 54s\n","247:\tlearn: 0.3958374\ttotal: 37.7s\tremaining: 1m 54s\n","248:\tlearn: 0.3958139\ttotal: 37.9s\tremaining: 1m 54s\n","249:\tlearn: 0.3957997\ttotal: 38s\tremaining: 1m 54s\n","250:\tlearn: 0.3957631\ttotal: 38.2s\tremaining: 1m 53s\n","251:\tlearn: 0.3957231\ttotal: 38.3s\tremaining: 1m 53s\n","252:\tlearn: 0.3957063\ttotal: 38.4s\tremaining: 1m 53s\n","253:\tlearn: 0.3956891\ttotal: 38.6s\tremaining: 1m 53s\n","254:\tlearn: 0.3956490\ttotal: 38.7s\tremaining: 1m 53s\n","255:\tlearn: 0.3956320\ttotal: 38.9s\tremaining: 1m 52s\n","256:\tlearn: 0.3955965\ttotal: 39s\tremaining: 1m 52s\n","257:\tlearn: 0.3955805\ttotal: 39.2s\tremaining: 1m 52s\n","258:\tlearn: 0.3955401\ttotal: 39.3s\tremaining: 1m 52s\n","259:\tlearn: 0.3955167\ttotal: 39.5s\tremaining: 1m 52s\n","260:\tlearn: 0.3954950\ttotal: 39.6s\tremaining: 1m 52s\n","261:\tlearn: 0.3954731\ttotal: 39.8s\tremaining: 1m 52s\n","262:\tlearn: 0.3954426\ttotal: 40s\tremaining: 1m 51s\n","263:\tlearn: 0.3954190\ttotal: 40.1s\tremaining: 1m 51s\n","264:\tlearn: 0.3953993\ttotal: 40.3s\tremaining: 1m 51s\n","265:\tlearn: 0.3953818\ttotal: 40.4s\tremaining: 1m 51s\n","266:\tlearn: 0.3953719\ttotal: 40.5s\tremaining: 1m 51s\n","267:\tlearn: 0.3953605\ttotal: 40.7s\tremaining: 1m 51s\n","268:\tlearn: 0.3953281\ttotal: 40.9s\tremaining: 1m 51s\n","269:\tlearn: 0.3953061\ttotal: 41s\tremaining: 1m 50s\n","270:\tlearn: 0.3952807\ttotal: 41.1s\tremaining: 1m 50s\n","271:\tlearn: 0.3952683\ttotal: 41.3s\tremaining: 1m 50s\n","272:\tlearn: 0.3952417\ttotal: 41.4s\tremaining: 1m 50s\n","273:\tlearn: 0.3952102\ttotal: 41.6s\tremaining: 1m 50s\n","274:\tlearn: 0.3951965\ttotal: 41.7s\tremaining: 1m 50s\n","275:\tlearn: 0.3951729\ttotal: 41.9s\tremaining: 1m 49s\n","276:\tlearn: 0.3951474\ttotal: 42.1s\tremaining: 1m 49s\n","277:\tlearn: 0.3951235\ttotal: 42.3s\tremaining: 1m 49s\n","278:\tlearn: 0.3951023\ttotal: 42.4s\tremaining: 1m 49s\n","279:\tlearn: 0.3950921\ttotal: 42.6s\tremaining: 1m 49s\n","280:\tlearn: 0.3950625\ttotal: 42.7s\tremaining: 1m 49s\n","281:\tlearn: 0.3950395\ttotal: 42.9s\tremaining: 1m 49s\n","282:\tlearn: 0.3950070\ttotal: 43s\tremaining: 1m 48s\n","283:\tlearn: 0.3949830\ttotal: 43.1s\tremaining: 1m 48s\n","284:\tlearn: 0.3949651\ttotal: 43.3s\tremaining: 1m 48s\n","285:\tlearn: 0.3949569\ttotal: 43.4s\tremaining: 1m 48s\n","286:\tlearn: 0.3949436\ttotal: 43.5s\tremaining: 1m 48s\n","287:\tlearn: 0.3949253\ttotal: 43.7s\tremaining: 1m 48s\n","288:\tlearn: 0.3949065\ttotal: 43.9s\tremaining: 1m 47s\n","289:\tlearn: 0.3948911\ttotal: 44s\tremaining: 1m 47s\n","290:\tlearn: 0.3948774\ttotal: 44.2s\tremaining: 1m 47s\n","291:\tlearn: 0.3948620\ttotal: 44.3s\tremaining: 1m 47s\n","292:\tlearn: 0.3948506\ttotal: 44.4s\tremaining: 1m 47s\n","293:\tlearn: 0.3948303\ttotal: 44.6s\tremaining: 1m 47s\n","294:\tlearn: 0.3948233\ttotal: 44.7s\tremaining: 1m 46s\n","295:\tlearn: 0.3948147\ttotal: 44.8s\tremaining: 1m 46s\n","296:\tlearn: 0.3948050\ttotal: 45s\tremaining: 1m 46s\n","297:\tlearn: 0.3947900\ttotal: 45.1s\tremaining: 1m 46s\n","298:\tlearn: 0.3947700\ttotal: 45.2s\tremaining: 1m 46s\n","299:\tlearn: 0.3947560\ttotal: 45.4s\tremaining: 1m 45s\n","300:\tlearn: 0.3947419\ttotal: 45.6s\tremaining: 1m 45s\n","301:\tlearn: 0.3947360\ttotal: 45.7s\tremaining: 1m 45s\n","302:\tlearn: 0.3947221\ttotal: 45.8s\tremaining: 1m 45s\n","303:\tlearn: 0.3947060\ttotal: 46s\tremaining: 1m 45s\n","304:\tlearn: 0.3946875\ttotal: 46.1s\tremaining: 1m 45s\n","305:\tlearn: 0.3946776\ttotal: 46.2s\tremaining: 1m 44s\n","306:\tlearn: 0.3946603\ttotal: 46.4s\tremaining: 1m 44s\n","307:\tlearn: 0.3946425\ttotal: 46.5s\tremaining: 1m 44s\n","308:\tlearn: 0.3946213\ttotal: 46.7s\tremaining: 1m 44s\n","309:\tlearn: 0.3946057\ttotal: 46.8s\tremaining: 1m 44s\n","310:\tlearn: 0.3945855\ttotal: 46.9s\tremaining: 1m 43s\n","311:\tlearn: 0.3945705\ttotal: 47.1s\tremaining: 1m 43s\n","312:\tlearn: 0.3945242\ttotal: 47.2s\tremaining: 1m 43s\n","313:\tlearn: 0.3944999\ttotal: 47.3s\tremaining: 1m 43s\n","314:\tlearn: 0.3944804\ttotal: 47.5s\tremaining: 1m 43s\n","315:\tlearn: 0.3944632\ttotal: 47.6s\tremaining: 1m 43s\n","316:\tlearn: 0.3944462\ttotal: 47.8s\tremaining: 1m 43s\n","317:\tlearn: 0.3944304\ttotal: 48s\tremaining: 1m 42s\n","318:\tlearn: 0.3943890\ttotal: 48.2s\tremaining: 1m 42s\n","319:\tlearn: 0.3943784\ttotal: 48.3s\tremaining: 1m 42s\n","320:\tlearn: 0.3943673\ttotal: 48.5s\tremaining: 1m 42s\n","321:\tlearn: 0.3943423\ttotal: 48.7s\tremaining: 1m 42s\n","322:\tlearn: 0.3943230\ttotal: 48.8s\tremaining: 1m 42s\n","323:\tlearn: 0.3943082\ttotal: 49s\tremaining: 1m 42s\n","324:\tlearn: 0.3942968\ttotal: 49.1s\tremaining: 1m 41s\n","325:\tlearn: 0.3942857\ttotal: 49.2s\tremaining: 1m 41s\n","326:\tlearn: 0.3942746\ttotal: 49.4s\tremaining: 1m 41s\n","327:\tlearn: 0.3942666\ttotal: 49.5s\tremaining: 1m 41s\n","328:\tlearn: 0.3942442\ttotal: 49.8s\tremaining: 1m 41s\n","329:\tlearn: 0.3942302\ttotal: 49.9s\tremaining: 1m 41s\n","330:\tlearn: 0.3942066\ttotal: 50.1s\tremaining: 1m 41s\n","331:\tlearn: 0.3941985\ttotal: 50.2s\tremaining: 1m 41s\n","332:\tlearn: 0.3941854\ttotal: 50.3s\tremaining: 1m 40s\n","333:\tlearn: 0.3941689\ttotal: 50.5s\tremaining: 1m 40s\n","334:\tlearn: 0.3941561\ttotal: 50.7s\tremaining: 1m 40s\n","335:\tlearn: 0.3941445\ttotal: 50.8s\tremaining: 1m 40s\n","336:\tlearn: 0.3941373\ttotal: 51s\tremaining: 1m 40s\n","337:\tlearn: 0.3941194\ttotal: 51.1s\tremaining: 1m 40s\n","338:\tlearn: 0.3941093\ttotal: 51.3s\tremaining: 1m 39s\n","339:\tlearn: 0.3940978\ttotal: 51.4s\tremaining: 1m 39s\n","340:\tlearn: 0.3940840\ttotal: 51.6s\tremaining: 1m 39s\n","341:\tlearn: 0.3940672\ttotal: 51.7s\tremaining: 1m 39s\n","342:\tlearn: 0.3940464\ttotal: 51.9s\tremaining: 1m 39s\n","343:\tlearn: 0.3940292\ttotal: 52s\tremaining: 1m 39s\n","344:\tlearn: 0.3940115\ttotal: 52.2s\tremaining: 1m 39s\n","345:\tlearn: 0.3939931\ttotal: 52.3s\tremaining: 1m 38s\n","346:\tlearn: 0.3939839\ttotal: 52.5s\tremaining: 1m 38s\n","347:\tlearn: 0.3939760\ttotal: 52.6s\tremaining: 1m 38s\n","348:\tlearn: 0.3939576\ttotal: 52.8s\tremaining: 1m 38s\n","349:\tlearn: 0.3939505\ttotal: 52.9s\tremaining: 1m 38s\n","350:\tlearn: 0.3939260\ttotal: 53.1s\tremaining: 1m 38s\n","351:\tlearn: 0.3939144\ttotal: 53.2s\tremaining: 1m 37s\n","352:\tlearn: 0.3938909\ttotal: 53.4s\tremaining: 1m 37s\n","353:\tlearn: 0.3938779\ttotal: 53.5s\tremaining: 1m 37s\n","354:\tlearn: 0.3938534\ttotal: 53.7s\tremaining: 1m 37s\n","355:\tlearn: 0.3938319\ttotal: 53.8s\tremaining: 1m 37s\n","356:\tlearn: 0.3938249\ttotal: 54s\tremaining: 1m 37s\n","357:\tlearn: 0.3938115\ttotal: 54.1s\tremaining: 1m 37s\n","358:\tlearn: 0.3937944\ttotal: 54.3s\tremaining: 1m 36s\n","359:\tlearn: 0.3937817\ttotal: 54.5s\tremaining: 1m 36s\n","360:\tlearn: 0.3937705\ttotal: 54.7s\tremaining: 1m 36s\n","361:\tlearn: 0.3937427\ttotal: 54.9s\tremaining: 1m 36s\n","362:\tlearn: 0.3937315\ttotal: 55s\tremaining: 1m 36s\n","363:\tlearn: 0.3937226\ttotal: 55.2s\tremaining: 1m 36s\n","364:\tlearn: 0.3937154\ttotal: 55.3s\tremaining: 1m 36s\n","365:\tlearn: 0.3937048\ttotal: 55.5s\tremaining: 1m 36s\n","366:\tlearn: 0.3936857\ttotal: 55.6s\tremaining: 1m 35s\n","367:\tlearn: 0.3936756\ttotal: 55.8s\tremaining: 1m 35s\n","368:\tlearn: 0.3936615\ttotal: 55.9s\tremaining: 1m 35s\n","369:\tlearn: 0.3936456\ttotal: 56.1s\tremaining: 1m 35s\n","370:\tlearn: 0.3936360\ttotal: 56.3s\tremaining: 1m 35s\n","371:\tlearn: 0.3936241\ttotal: 56.5s\tremaining: 1m 35s\n","372:\tlearn: 0.3936131\ttotal: 56.8s\tremaining: 1m 35s\n","373:\tlearn: 0.3935980\ttotal: 57s\tremaining: 1m 35s\n","374:\tlearn: 0.3935713\ttotal: 57.1s\tremaining: 1m 35s\n","375:\tlearn: 0.3935612\ttotal: 57.3s\tremaining: 1m 35s\n","376:\tlearn: 0.3935584\ttotal: 57.4s\tremaining: 1m 34s\n","377:\tlearn: 0.3935503\ttotal: 57.5s\tremaining: 1m 34s\n","378:\tlearn: 0.3935065\ttotal: 57.7s\tremaining: 1m 34s\n","379:\tlearn: 0.3934969\ttotal: 57.8s\tremaining: 1m 34s\n","380:\tlearn: 0.3934773\ttotal: 58s\tremaining: 1m 34s\n","381:\tlearn: 0.3934611\ttotal: 58.2s\tremaining: 1m 34s\n","382:\tlearn: 0.3934380\ttotal: 58.3s\tremaining: 1m 33s\n","383:\tlearn: 0.3934205\ttotal: 58.5s\tremaining: 1m 33s\n","384:\tlearn: 0.3934150\ttotal: 58.7s\tremaining: 1m 33s\n","385:\tlearn: 0.3934022\ttotal: 58.9s\tremaining: 1m 33s\n","386:\tlearn: 0.3933929\ttotal: 59s\tremaining: 1m 33s\n","387:\tlearn: 0.3933788\ttotal: 59.2s\tremaining: 1m 33s\n","388:\tlearn: 0.3933646\ttotal: 59.4s\tremaining: 1m 33s\n","389:\tlearn: 0.3933520\ttotal: 59.6s\tremaining: 1m 33s\n","390:\tlearn: 0.3933400\ttotal: 59.7s\tremaining: 1m 33s\n","391:\tlearn: 0.3933261\ttotal: 59.9s\tremaining: 1m 32s\n","392:\tlearn: 0.3933153\ttotal: 1m\tremaining: 1m 32s\n","393:\tlearn: 0.3933096\ttotal: 1m\tremaining: 1m 32s\n","394:\tlearn: 0.3932950\ttotal: 1m\tremaining: 1m 32s\n","395:\tlearn: 0.3932852\ttotal: 1m\tremaining: 1m 32s\n","396:\tlearn: 0.3932742\ttotal: 1m\tremaining: 1m 32s\n","397:\tlearn: 0.3932604\ttotal: 1m\tremaining: 1m 31s\n","398:\tlearn: 0.3932549\ttotal: 1m\tremaining: 1m 31s\n","399:\tlearn: 0.3932403\ttotal: 1m 1s\tremaining: 1m 31s\n","400:\tlearn: 0.3932222\ttotal: 1m 1s\tremaining: 1m 31s\n","401:\tlearn: 0.3932067\ttotal: 1m 1s\tremaining: 1m 31s\n","402:\tlearn: 0.3931939\ttotal: 1m 1s\tremaining: 1m 31s\n","403:\tlearn: 0.3931723\ttotal: 1m 1s\tremaining: 1m 30s\n","404:\tlearn: 0.3931649\ttotal: 1m 1s\tremaining: 1m 30s\n","405:\tlearn: 0.3931515\ttotal: 1m 1s\tremaining: 1m 30s\n","406:\tlearn: 0.3931435\ttotal: 1m 2s\tremaining: 1m 30s\n","407:\tlearn: 0.3931261\ttotal: 1m 2s\tremaining: 1m 30s\n","408:\tlearn: 0.3931134\ttotal: 1m 2s\tremaining: 1m 30s\n","409:\tlearn: 0.3931062\ttotal: 1m 2s\tremaining: 1m 30s\n","410:\tlearn: 0.3930972\ttotal: 1m 2s\tremaining: 1m 30s\n","411:\tlearn: 0.3930825\ttotal: 1m 2s\tremaining: 1m 29s\n","412:\tlearn: 0.3930655\ttotal: 1m 3s\tremaining: 1m 29s\n","413:\tlearn: 0.3930500\ttotal: 1m 3s\tremaining: 1m 29s\n","414:\tlearn: 0.3930404\ttotal: 1m 3s\tremaining: 1m 29s\n","415:\tlearn: 0.3930348\ttotal: 1m 3s\tremaining: 1m 29s\n","416:\tlearn: 0.3930249\ttotal: 1m 3s\tremaining: 1m 29s\n","417:\tlearn: 0.3930175\ttotal: 1m 3s\tremaining: 1m 28s\n","418:\tlearn: 0.3930042\ttotal: 1m 3s\tremaining: 1m 28s\n","419:\tlearn: 0.3929927\ttotal: 1m 4s\tremaining: 1m 28s\n","420:\tlearn: 0.3929784\ttotal: 1m 4s\tremaining: 1m 28s\n","421:\tlearn: 0.3929619\ttotal: 1m 4s\tremaining: 1m 28s\n","422:\tlearn: 0.3929513\ttotal: 1m 4s\tremaining: 1m 28s\n","423:\tlearn: 0.3929383\ttotal: 1m 4s\tremaining: 1m 27s\n","424:\tlearn: 0.3929234\ttotal: 1m 4s\tremaining: 1m 27s\n","425:\tlearn: 0.3929102\ttotal: 1m 5s\tremaining: 1m 27s\n","426:\tlearn: 0.3928992\ttotal: 1m 5s\tremaining: 1m 27s\n","427:\tlearn: 0.3928841\ttotal: 1m 5s\tremaining: 1m 27s\n","428:\tlearn: 0.3928753\ttotal: 1m 5s\tremaining: 1m 27s\n","429:\tlearn: 0.3928653\ttotal: 1m 5s\tremaining: 1m 27s\n","430:\tlearn: 0.3928473\ttotal: 1m 5s\tremaining: 1m 26s\n","431:\tlearn: 0.3928355\ttotal: 1m 6s\tremaining: 1m 26s\n","432:\tlearn: 0.3928263\ttotal: 1m 6s\tremaining: 1m 26s\n","433:\tlearn: 0.3928119\ttotal: 1m 6s\tremaining: 1m 26s\n","434:\tlearn: 0.3928031\ttotal: 1m 6s\tremaining: 1m 26s\n","435:\tlearn: 0.3927944\ttotal: 1m 6s\tremaining: 1m 26s\n","436:\tlearn: 0.3927824\ttotal: 1m 6s\tremaining: 1m 26s\n","437:\tlearn: 0.3927747\ttotal: 1m 7s\tremaining: 1m 25s\n","438:\tlearn: 0.3927664\ttotal: 1m 7s\tremaining: 1m 25s\n","439:\tlearn: 0.3927540\ttotal: 1m 7s\tremaining: 1m 25s\n","440:\tlearn: 0.3927427\ttotal: 1m 7s\tremaining: 1m 25s\n","441:\tlearn: 0.3927290\ttotal: 1m 7s\tremaining: 1m 25s\n","442:\tlearn: 0.3927200\ttotal: 1m 7s\tremaining: 1m 25s\n","443:\tlearn: 0.3927133\ttotal: 1m 7s\tremaining: 1m 25s\n","444:\tlearn: 0.3926990\ttotal: 1m 8s\tremaining: 1m 24s\n","445:\tlearn: 0.3926900\ttotal: 1m 8s\tremaining: 1m 24s\n","446:\tlearn: 0.3926765\ttotal: 1m 8s\tremaining: 1m 24s\n","447:\tlearn: 0.3926705\ttotal: 1m 8s\tremaining: 1m 24s\n","448:\tlearn: 0.3926593\ttotal: 1m 8s\tremaining: 1m 24s\n","449:\tlearn: 0.3926493\ttotal: 1m 8s\tremaining: 1m 24s\n","450:\tlearn: 0.3926395\ttotal: 1m 8s\tremaining: 1m 23s\n","451:\tlearn: 0.3926287\ttotal: 1m 9s\tremaining: 1m 23s\n","452:\tlearn: 0.3926221\ttotal: 1m 9s\tremaining: 1m 23s\n","453:\tlearn: 0.3926147\ttotal: 1m 9s\tremaining: 1m 23s\n","454:\tlearn: 0.3926039\ttotal: 1m 9s\tremaining: 1m 23s\n","455:\tlearn: 0.3925963\ttotal: 1m 9s\tremaining: 1m 23s\n","456:\tlearn: 0.3925761\ttotal: 1m 9s\tremaining: 1m 23s\n","457:\tlearn: 0.3925666\ttotal: 1m 10s\tremaining: 1m 22s\n","458:\tlearn: 0.3925593\ttotal: 1m 10s\tremaining: 1m 22s\n","459:\tlearn: 0.3925522\ttotal: 1m 10s\tremaining: 1m 22s\n","460:\tlearn: 0.3925400\ttotal: 1m 10s\tremaining: 1m 22s\n","461:\tlearn: 0.3925390\ttotal: 1m 10s\tremaining: 1m 22s\n","462:\tlearn: 0.3925344\ttotal: 1m 10s\tremaining: 1m 22s\n","463:\tlearn: 0.3925262\ttotal: 1m 10s\tremaining: 1m 21s\n","464:\tlearn: 0.3925200\ttotal: 1m 11s\tremaining: 1m 21s\n","465:\tlearn: 0.3925142\ttotal: 1m 11s\tremaining: 1m 21s\n","466:\tlearn: 0.3925012\ttotal: 1m 11s\tremaining: 1m 21s\n","467:\tlearn: 0.3924917\ttotal: 1m 11s\tremaining: 1m 21s\n","468:\tlearn: 0.3924781\ttotal: 1m 11s\tremaining: 1m 21s\n","469:\tlearn: 0.3924639\ttotal: 1m 11s\tremaining: 1m 21s\n","470:\tlearn: 0.3924531\ttotal: 1m 12s\tremaining: 1m 20s\n","471:\tlearn: 0.3924449\ttotal: 1m 12s\tremaining: 1m 20s\n","472:\tlearn: 0.3924308\ttotal: 1m 12s\tremaining: 1m 20s\n","473:\tlearn: 0.3924196\ttotal: 1m 12s\tremaining: 1m 20s\n","474:\tlearn: 0.3924036\ttotal: 1m 12s\tremaining: 1m 20s\n","475:\tlearn: 0.3923917\ttotal: 1m 12s\tremaining: 1m 20s\n","476:\tlearn: 0.3923817\ttotal: 1m 12s\tremaining: 1m 19s\n","477:\tlearn: 0.3923771\ttotal: 1m 13s\tremaining: 1m 19s\n","478:\tlearn: 0.3923706\ttotal: 1m 13s\tremaining: 1m 19s\n","479:\tlearn: 0.3923630\ttotal: 1m 13s\tremaining: 1m 19s\n","480:\tlearn: 0.3923540\ttotal: 1m 13s\tremaining: 1m 19s\n","481:\tlearn: 0.3923451\ttotal: 1m 13s\tremaining: 1m 19s\n","482:\tlearn: 0.3923352\ttotal: 1m 13s\tremaining: 1m 18s\n","483:\tlearn: 0.3923311\ttotal: 1m 13s\tremaining: 1m 18s\n","484:\tlearn: 0.3923245\ttotal: 1m 14s\tremaining: 1m 18s\n","485:\tlearn: 0.3923076\ttotal: 1m 14s\tremaining: 1m 18s\n","486:\tlearn: 0.3922998\ttotal: 1m 14s\tremaining: 1m 18s\n","487:\tlearn: 0.3922896\ttotal: 1m 14s\tremaining: 1m 18s\n","488:\tlearn: 0.3922790\ttotal: 1m 14s\tremaining: 1m 17s\n","489:\tlearn: 0.3922606\ttotal: 1m 14s\tremaining: 1m 17s\n","490:\tlearn: 0.3922456\ttotal: 1m 14s\tremaining: 1m 17s\n","491:\tlearn: 0.3922345\ttotal: 1m 15s\tremaining: 1m 17s\n","492:\tlearn: 0.3922230\ttotal: 1m 15s\tremaining: 1m 17s\n","493:\tlearn: 0.3922109\ttotal: 1m 15s\tremaining: 1m 17s\n","494:\tlearn: 0.3922028\ttotal: 1m 15s\tremaining: 1m 17s\n","495:\tlearn: 0.3921904\ttotal: 1m 15s\tremaining: 1m 16s\n","496:\tlearn: 0.3921800\ttotal: 1m 15s\tremaining: 1m 16s\n","497:\tlearn: 0.3921720\ttotal: 1m 15s\tremaining: 1m 16s\n","498:\tlearn: 0.3921595\ttotal: 1m 16s\tremaining: 1m 16s\n","499:\tlearn: 0.3921518\ttotal: 1m 16s\tremaining: 1m 16s\n","500:\tlearn: 0.3921390\ttotal: 1m 16s\tremaining: 1m 16s\n","501:\tlearn: 0.3921259\ttotal: 1m 16s\tremaining: 1m 15s\n","502:\tlearn: 0.3921223\ttotal: 1m 16s\tremaining: 1m 15s\n","503:\tlearn: 0.3921117\ttotal: 1m 16s\tremaining: 1m 15s\n","504:\tlearn: 0.3921011\ttotal: 1m 16s\tremaining: 1m 15s\n","505:\tlearn: 0.3920942\ttotal: 1m 16s\tremaining: 1m 15s\n","506:\tlearn: 0.3920788\ttotal: 1m 17s\tremaining: 1m 15s\n","507:\tlearn: 0.3920692\ttotal: 1m 17s\tremaining: 1m 14s\n","508:\tlearn: 0.3920608\ttotal: 1m 17s\tremaining: 1m 14s\n","509:\tlearn: 0.3920416\ttotal: 1m 17s\tremaining: 1m 14s\n","510:\tlearn: 0.3920402\ttotal: 1m 17s\tremaining: 1m 14s\n","511:\tlearn: 0.3920350\ttotal: 1m 17s\tremaining: 1m 14s\n","512:\tlearn: 0.3920161\ttotal: 1m 18s\tremaining: 1m 14s\n","513:\tlearn: 0.3920068\ttotal: 1m 18s\tremaining: 1m 14s\n","514:\tlearn: 0.3919953\ttotal: 1m 18s\tremaining: 1m 13s\n","515:\tlearn: 0.3919886\ttotal: 1m 18s\tremaining: 1m 13s\n","516:\tlearn: 0.3919780\ttotal: 1m 18s\tremaining: 1m 13s\n","517:\tlearn: 0.3919644\ttotal: 1m 18s\tremaining: 1m 13s\n","518:\tlearn: 0.3919486\ttotal: 1m 19s\tremaining: 1m 13s\n","519:\tlearn: 0.3919380\ttotal: 1m 19s\tremaining: 1m 13s\n","520:\tlearn: 0.3919304\ttotal: 1m 19s\tremaining: 1m 13s\n","521:\tlearn: 0.3919237\ttotal: 1m 19s\tremaining: 1m 12s\n","522:\tlearn: 0.3919123\ttotal: 1m 19s\tremaining: 1m 12s\n","523:\tlearn: 0.3919001\ttotal: 1m 19s\tremaining: 1m 12s\n","524:\tlearn: 0.3918938\ttotal: 1m 19s\tremaining: 1m 12s\n","525:\tlearn: 0.3918872\ttotal: 1m 20s\tremaining: 1m 12s\n","526:\tlearn: 0.3918779\ttotal: 1m 20s\tremaining: 1m 12s\n","527:\tlearn: 0.3918723\ttotal: 1m 20s\tremaining: 1m 11s\n","528:\tlearn: 0.3918623\ttotal: 1m 20s\tremaining: 1m 11s\n","529:\tlearn: 0.3918331\ttotal: 1m 20s\tremaining: 1m 11s\n","530:\tlearn: 0.3918243\ttotal: 1m 20s\tremaining: 1m 11s\n","531:\tlearn: 0.3918106\ttotal: 1m 20s\tremaining: 1m 11s\n","532:\tlearn: 0.3918056\ttotal: 1m 21s\tremaining: 1m 11s\n","533:\tlearn: 0.3917947\ttotal: 1m 21s\tremaining: 1m 10s\n","534:\tlearn: 0.3917674\ttotal: 1m 21s\tremaining: 1m 10s\n","535:\tlearn: 0.3917598\ttotal: 1m 21s\tremaining: 1m 10s\n","536:\tlearn: 0.3917492\ttotal: 1m 21s\tremaining: 1m 10s\n","537:\tlearn: 0.3917397\ttotal: 1m 21s\tremaining: 1m 10s\n","538:\tlearn: 0.3917266\ttotal: 1m 22s\tremaining: 1m 10s\n","539:\tlearn: 0.3917117\ttotal: 1m 22s\tremaining: 1m 9s\n","540:\tlearn: 0.3917065\ttotal: 1m 22s\tremaining: 1m 9s\n","541:\tlearn: 0.3916982\ttotal: 1m 22s\tremaining: 1m 9s\n","542:\tlearn: 0.3916896\ttotal: 1m 22s\tremaining: 1m 9s\n","543:\tlearn: 0.3916800\ttotal: 1m 22s\tremaining: 1m 9s\n","544:\tlearn: 0.3916657\ttotal: 1m 22s\tremaining: 1m 9s\n","545:\tlearn: 0.3916568\ttotal: 1m 23s\tremaining: 1m 9s\n","546:\tlearn: 0.3916508\ttotal: 1m 23s\tremaining: 1m 8s\n","547:\tlearn: 0.3916418\ttotal: 1m 23s\tremaining: 1m 8s\n","548:\tlearn: 0.3916332\ttotal: 1m 23s\tremaining: 1m 8s\n","549:\tlearn: 0.3916217\ttotal: 1m 23s\tremaining: 1m 8s\n","550:\tlearn: 0.3916121\ttotal: 1m 23s\tremaining: 1m 8s\n","551:\tlearn: 0.3916077\ttotal: 1m 23s\tremaining: 1m 8s\n","552:\tlearn: 0.3915970\ttotal: 1m 24s\tremaining: 1m 7s\n","553:\tlearn: 0.3915887\ttotal: 1m 24s\tremaining: 1m 7s\n","554:\tlearn: 0.3915814\ttotal: 1m 24s\tremaining: 1m 7s\n","555:\tlearn: 0.3915677\ttotal: 1m 24s\tremaining: 1m 7s\n","556:\tlearn: 0.3915564\ttotal: 1m 24s\tremaining: 1m 7s\n","557:\tlearn: 0.3915506\ttotal: 1m 24s\tremaining: 1m 7s\n","558:\tlearn: 0.3915241\ttotal: 1m 24s\tremaining: 1m 7s\n","559:\tlearn: 0.3915146\ttotal: 1m 25s\tremaining: 1m 6s\n","560:\tlearn: 0.3915085\ttotal: 1m 25s\tremaining: 1m 6s\n","561:\tlearn: 0.3915006\ttotal: 1m 25s\tremaining: 1m 6s\n","562:\tlearn: 0.3914917\ttotal: 1m 25s\tremaining: 1m 6s\n","563:\tlearn: 0.3914826\ttotal: 1m 25s\tremaining: 1m 6s\n","564:\tlearn: 0.3914773\ttotal: 1m 25s\tremaining: 1m 6s\n","565:\tlearn: 0.3914667\ttotal: 1m 26s\tremaining: 1m 5s\n","566:\tlearn: 0.3914600\ttotal: 1m 26s\tremaining: 1m 5s\n","567:\tlearn: 0.3914532\ttotal: 1m 26s\tremaining: 1m 5s\n","568:\tlearn: 0.3914486\ttotal: 1m 26s\tremaining: 1m 5s\n","569:\tlearn: 0.3914397\ttotal: 1m 26s\tremaining: 1m 5s\n","570:\tlearn: 0.3914313\ttotal: 1m 26s\tremaining: 1m 5s\n","571:\tlearn: 0.3914193\ttotal: 1m 26s\tremaining: 1m 5s\n","572:\tlearn: 0.3914055\ttotal: 1m 27s\tremaining: 1m 4s\n","573:\tlearn: 0.3913923\ttotal: 1m 27s\tremaining: 1m 4s\n","574:\tlearn: 0.3913812\ttotal: 1m 27s\tremaining: 1m 4s\n","575:\tlearn: 0.3913690\ttotal: 1m 27s\tremaining: 1m 4s\n","576:\tlearn: 0.3913607\ttotal: 1m 27s\tremaining: 1m 4s\n","577:\tlearn: 0.3913510\ttotal: 1m 28s\tremaining: 1m 4s\n","578:\tlearn: 0.3913429\ttotal: 1m 28s\tremaining: 1m 4s\n","579:\tlearn: 0.3913384\ttotal: 1m 28s\tremaining: 1m 3s\n","580:\tlearn: 0.3913299\ttotal: 1m 28s\tremaining: 1m 3s\n","581:\tlearn: 0.3913212\ttotal: 1m 28s\tremaining: 1m 3s\n","582:\tlearn: 0.3913134\ttotal: 1m 28s\tremaining: 1m 3s\n","583:\tlearn: 0.3913077\ttotal: 1m 28s\tremaining: 1m 3s\n","584:\tlearn: 0.3912991\ttotal: 1m 29s\tremaining: 1m 3s\n","585:\tlearn: 0.3912932\ttotal: 1m 29s\tremaining: 1m 3s\n","586:\tlearn: 0.3912848\ttotal: 1m 29s\tremaining: 1m 2s\n","587:\tlearn: 0.3912768\ttotal: 1m 29s\tremaining: 1m 2s\n","588:\tlearn: 0.3912691\ttotal: 1m 29s\tremaining: 1m 2s\n","589:\tlearn: 0.3912606\ttotal: 1m 29s\tremaining: 1m 2s\n","590:\tlearn: 0.3912481\ttotal: 1m 29s\tremaining: 1m 2s\n","591:\tlearn: 0.3912401\ttotal: 1m 30s\tremaining: 1m 2s\n","592:\tlearn: 0.3912336\ttotal: 1m 30s\tremaining: 1m 1s\n","593:\tlearn: 0.3912253\ttotal: 1m 30s\tremaining: 1m 1s\n","594:\tlearn: 0.3912174\ttotal: 1m 30s\tremaining: 1m 1s\n","595:\tlearn: 0.3912082\ttotal: 1m 30s\tremaining: 1m 1s\n","596:\tlearn: 0.3911966\ttotal: 1m 30s\tremaining: 1m 1s\n","597:\tlearn: 0.3911906\ttotal: 1m 30s\tremaining: 1m 1s\n","598:\tlearn: 0.3911843\ttotal: 1m 31s\tremaining: 1m\n","599:\tlearn: 0.3911756\ttotal: 1m 31s\tremaining: 1m\n","600:\tlearn: 0.3911668\ttotal: 1m 31s\tremaining: 1m\n","601:\tlearn: 0.3911595\ttotal: 1m 31s\tremaining: 1m\n","602:\tlearn: 0.3911532\ttotal: 1m 31s\tremaining: 1m\n","603:\tlearn: 0.3911454\ttotal: 1m 31s\tremaining: 1m\n","604:\tlearn: 0.3911384\ttotal: 1m 31s\tremaining: 1m\n","605:\tlearn: 0.3911314\ttotal: 1m 32s\tremaining: 59.9s\n","606:\tlearn: 0.3911228\ttotal: 1m 32s\tremaining: 59.7s\n","607:\tlearn: 0.3911181\ttotal: 1m 32s\tremaining: 59.6s\n","608:\tlearn: 0.3911053\ttotal: 1m 32s\tremaining: 59.4s\n","609:\tlearn: 0.3910976\ttotal: 1m 32s\tremaining: 59.3s\n","610:\tlearn: 0.3910912\ttotal: 1m 32s\tremaining: 59.2s\n","611:\tlearn: 0.3910846\ttotal: 1m 33s\tremaining: 59s\n","612:\tlearn: 0.3910793\ttotal: 1m 33s\tremaining: 58.9s\n","613:\tlearn: 0.3910702\ttotal: 1m 33s\tremaining: 58.7s\n","614:\tlearn: 0.3910652\ttotal: 1m 33s\tremaining: 58.5s\n","615:\tlearn: 0.3910590\ttotal: 1m 33s\tremaining: 58.4s\n","616:\tlearn: 0.3910520\ttotal: 1m 33s\tremaining: 58.3s\n","617:\tlearn: 0.3910468\ttotal: 1m 34s\tremaining: 58.1s\n","618:\tlearn: 0.3910378\ttotal: 1m 34s\tremaining: 57.9s\n","619:\tlearn: 0.3910231\ttotal: 1m 34s\tremaining: 57.8s\n","620:\tlearn: 0.3910086\ttotal: 1m 34s\tremaining: 57.6s\n","621:\tlearn: 0.3910024\ttotal: 1m 34s\tremaining: 57.5s\n","622:\tlearn: 0.3909947\ttotal: 1m 34s\tremaining: 57.3s\n","623:\tlearn: 0.3909859\ttotal: 1m 34s\tremaining: 57.2s\n","624:\tlearn: 0.3909745\ttotal: 1m 35s\tremaining: 57s\n","625:\tlearn: 0.3909669\ttotal: 1m 35s\tremaining: 56.9s\n","626:\tlearn: 0.3909580\ttotal: 1m 35s\tremaining: 56.7s\n","627:\tlearn: 0.3909492\ttotal: 1m 35s\tremaining: 56.6s\n","628:\tlearn: 0.3909353\ttotal: 1m 35s\tremaining: 56.4s\n","629:\tlearn: 0.3909247\ttotal: 1m 35s\tremaining: 56.2s\n","630:\tlearn: 0.3909172\ttotal: 1m 35s\tremaining: 56.1s\n","631:\tlearn: 0.3909090\ttotal: 1m 36s\tremaining: 55.9s\n","632:\tlearn: 0.3909017\ttotal: 1m 36s\tremaining: 55.8s\n","633:\tlearn: 0.3908925\ttotal: 1m 36s\tremaining: 55.6s\n","634:\tlearn: 0.3908838\ttotal: 1m 36s\tremaining: 55.5s\n","635:\tlearn: 0.3908743\ttotal: 1m 36s\tremaining: 55.3s\n","636:\tlearn: 0.3908654\ttotal: 1m 36s\tremaining: 55.2s\n","637:\tlearn: 0.3908568\ttotal: 1m 36s\tremaining: 55s\n","638:\tlearn: 0.3908516\ttotal: 1m 37s\tremaining: 54.9s\n","639:\tlearn: 0.3908457\ttotal: 1m 37s\tremaining: 54.7s\n","640:\tlearn: 0.3908378\ttotal: 1m 37s\tremaining: 54.5s\n","641:\tlearn: 0.3908310\ttotal: 1m 37s\tremaining: 54.4s\n","642:\tlearn: 0.3908247\ttotal: 1m 37s\tremaining: 54.2s\n","643:\tlearn: 0.3908162\ttotal: 1m 37s\tremaining: 54.1s\n","644:\tlearn: 0.3908101\ttotal: 1m 37s\tremaining: 53.9s\n","645:\tlearn: 0.3907974\ttotal: 1m 38s\tremaining: 53.8s\n","646:\tlearn: 0.3907928\ttotal: 1m 38s\tremaining: 53.6s\n","647:\tlearn: 0.3907832\ttotal: 1m 38s\tremaining: 53.5s\n","648:\tlearn: 0.3907742\ttotal: 1m 38s\tremaining: 53.3s\n","649:\tlearn: 0.3907655\ttotal: 1m 38s\tremaining: 53.2s\n","650:\tlearn: 0.3907582\ttotal: 1m 38s\tremaining: 53s\n","651:\tlearn: 0.3907478\ttotal: 1m 39s\tremaining: 52.9s\n","652:\tlearn: 0.3907416\ttotal: 1m 39s\tremaining: 52.7s\n","653:\tlearn: 0.3907288\ttotal: 1m 39s\tremaining: 52.6s\n","654:\tlearn: 0.3907223\ttotal: 1m 39s\tremaining: 52.4s\n","655:\tlearn: 0.3907133\ttotal: 1m 39s\tremaining: 52.3s\n","656:\tlearn: 0.3907065\ttotal: 1m 39s\tremaining: 52.1s\n","657:\tlearn: 0.3907013\ttotal: 1m 39s\tremaining: 51.9s\n","658:\tlearn: 0.3906954\ttotal: 1m 40s\tremaining: 51.8s\n","659:\tlearn: 0.3906922\ttotal: 1m 40s\tremaining: 51.6s\n","660:\tlearn: 0.3906843\ttotal: 1m 40s\tremaining: 51.5s\n","661:\tlearn: 0.3906801\ttotal: 1m 40s\tremaining: 51.3s\n","662:\tlearn: 0.3906733\ttotal: 1m 40s\tremaining: 51.2s\n","663:\tlearn: 0.3906614\ttotal: 1m 40s\tremaining: 51s\n","664:\tlearn: 0.3906472\ttotal: 1m 40s\tremaining: 50.9s\n","665:\tlearn: 0.3906396\ttotal: 1m 41s\tremaining: 50.7s\n","666:\tlearn: 0.3906334\ttotal: 1m 41s\tremaining: 50.6s\n","667:\tlearn: 0.3906243\ttotal: 1m 41s\tremaining: 50.4s\n","668:\tlearn: 0.3906151\ttotal: 1m 41s\tremaining: 50.3s\n","669:\tlearn: 0.3906101\ttotal: 1m 41s\tremaining: 50.1s\n","670:\tlearn: 0.3906047\ttotal: 1m 41s\tremaining: 50s\n","671:\tlearn: 0.3905976\ttotal: 1m 42s\tremaining: 49.8s\n","672:\tlearn: 0.3905913\ttotal: 1m 42s\tremaining: 49.7s\n","673:\tlearn: 0.3905825\ttotal: 1m 42s\tremaining: 49.5s\n","674:\tlearn: 0.3905751\ttotal: 1m 42s\tremaining: 49.3s\n","675:\tlearn: 0.3905694\ttotal: 1m 42s\tremaining: 49.2s\n","676:\tlearn: 0.3905590\ttotal: 1m 42s\tremaining: 49.1s\n","677:\tlearn: 0.3905539\ttotal: 1m 43s\tremaining: 48.9s\n","678:\tlearn: 0.3905448\ttotal: 1m 43s\tremaining: 48.8s\n","679:\tlearn: 0.3905249\ttotal: 1m 43s\tremaining: 48.7s\n","680:\tlearn: 0.3905209\ttotal: 1m 43s\tremaining: 48.5s\n","681:\tlearn: 0.3905149\ttotal: 1m 43s\tremaining: 48.4s\n","682:\tlearn: 0.3905116\ttotal: 1m 43s\tremaining: 48.2s\n","683:\tlearn: 0.3905045\ttotal: 1m 44s\tremaining: 48s\n","684:\tlearn: 0.3904992\ttotal: 1m 44s\tremaining: 47.9s\n","685:\tlearn: 0.3904933\ttotal: 1m 44s\tremaining: 47.7s\n","686:\tlearn: 0.3904830\ttotal: 1m 44s\tremaining: 47.6s\n","687:\tlearn: 0.3904740\ttotal: 1m 44s\tremaining: 47.4s\n","688:\tlearn: 0.3904663\ttotal: 1m 44s\tremaining: 47.3s\n","689:\tlearn: 0.3904565\ttotal: 1m 44s\tremaining: 47.1s\n","690:\tlearn: 0.3904500\ttotal: 1m 45s\tremaining: 47s\n","691:\tlearn: 0.3904442\ttotal: 1m 45s\tremaining: 46.8s\n","692:\tlearn: 0.3904340\ttotal: 1m 45s\tremaining: 46.6s\n","693:\tlearn: 0.3904257\ttotal: 1m 45s\tremaining: 46.5s\n","694:\tlearn: 0.3904195\ttotal: 1m 45s\tremaining: 46.3s\n","695:\tlearn: 0.3904128\ttotal: 1m 45s\tremaining: 46.2s\n","696:\tlearn: 0.3904091\ttotal: 1m 45s\tremaining: 46s\n","697:\tlearn: 0.3904006\ttotal: 1m 46s\tremaining: 45.9s\n","698:\tlearn: 0.3903929\ttotal: 1m 46s\tremaining: 45.7s\n","699:\tlearn: 0.3903863\ttotal: 1m 46s\tremaining: 45.6s\n","700:\tlearn: 0.3903777\ttotal: 1m 46s\tremaining: 45.4s\n","701:\tlearn: 0.3903721\ttotal: 1m 46s\tremaining: 45.3s\n","702:\tlearn: 0.3903681\ttotal: 1m 46s\tremaining: 45.1s\n","703:\tlearn: 0.3903613\ttotal: 1m 46s\tremaining: 45s\n","704:\tlearn: 0.3903570\ttotal: 1m 47s\tremaining: 44.8s\n","705:\tlearn: 0.3903506\ttotal: 1m 47s\tremaining: 44.6s\n","706:\tlearn: 0.3903459\ttotal: 1m 47s\tremaining: 44.5s\n","707:\tlearn: 0.3903401\ttotal: 1m 47s\tremaining: 44.3s\n","708:\tlearn: 0.3903340\ttotal: 1m 47s\tremaining: 44.2s\n","709:\tlearn: 0.3903273\ttotal: 1m 47s\tremaining: 44s\n","710:\tlearn: 0.3903156\ttotal: 1m 47s\tremaining: 43.9s\n","711:\tlearn: 0.3903076\ttotal: 1m 48s\tremaining: 43.7s\n","712:\tlearn: 0.3902999\ttotal: 1m 48s\tremaining: 43.6s\n","713:\tlearn: 0.3902914\ttotal: 1m 48s\tremaining: 43.4s\n","714:\tlearn: 0.3902876\ttotal: 1m 48s\tremaining: 43.3s\n","715:\tlearn: 0.3902809\ttotal: 1m 48s\tremaining: 43.1s\n","716:\tlearn: 0.3902702\ttotal: 1m 48s\tremaining: 42.9s\n","717:\tlearn: 0.3902650\ttotal: 1m 48s\tremaining: 42.8s\n","718:\tlearn: 0.3902580\ttotal: 1m 49s\tremaining: 42.6s\n","719:\tlearn: 0.3902496\ttotal: 1m 49s\tremaining: 42.5s\n","720:\tlearn: 0.3902455\ttotal: 1m 49s\tremaining: 42.3s\n","721:\tlearn: 0.3902405\ttotal: 1m 49s\tremaining: 42.2s\n","722:\tlearn: 0.3902333\ttotal: 1m 49s\tremaining: 42s\n","723:\tlearn: 0.3902276\ttotal: 1m 49s\tremaining: 41.9s\n","724:\tlearn: 0.3902198\ttotal: 1m 49s\tremaining: 41.7s\n","725:\tlearn: 0.3902112\ttotal: 1m 50s\tremaining: 41.6s\n","726:\tlearn: 0.3902054\ttotal: 1m 50s\tremaining: 41.4s\n","727:\tlearn: 0.3901999\ttotal: 1m 50s\tremaining: 41.3s\n","728:\tlearn: 0.3901935\ttotal: 1m 50s\tremaining: 41.1s\n","729:\tlearn: 0.3901851\ttotal: 1m 50s\tremaining: 41s\n","730:\tlearn: 0.3901780\ttotal: 1m 50s\tremaining: 40.8s\n","731:\tlearn: 0.3901712\ttotal: 1m 51s\tremaining: 40.7s\n","732:\tlearn: 0.3901606\ttotal: 1m 51s\tremaining: 40.5s\n","733:\tlearn: 0.3901545\ttotal: 1m 51s\tremaining: 40.4s\n","734:\tlearn: 0.3901413\ttotal: 1m 51s\tremaining: 40.2s\n","735:\tlearn: 0.3901321\ttotal: 1m 51s\tremaining: 40.1s\n","736:\tlearn: 0.3901221\ttotal: 1m 51s\tremaining: 39.9s\n","737:\tlearn: 0.3901116\ttotal: 1m 52s\tremaining: 39.8s\n","738:\tlearn: 0.3901035\ttotal: 1m 52s\tremaining: 39.6s\n","739:\tlearn: 0.3900982\ttotal: 1m 52s\tremaining: 39.5s\n","740:\tlearn: 0.3900793\ttotal: 1m 52s\tremaining: 39.3s\n","741:\tlearn: 0.3900674\ttotal: 1m 52s\tremaining: 39.2s\n","742:\tlearn: 0.3900560\ttotal: 1m 52s\tremaining: 39s\n","743:\tlearn: 0.3900510\ttotal: 1m 52s\tremaining: 38.9s\n","744:\tlearn: 0.3900375\ttotal: 1m 53s\tremaining: 38.7s\n","745:\tlearn: 0.3900337\ttotal: 1m 53s\tremaining: 38.6s\n","746:\tlearn: 0.3900275\ttotal: 1m 53s\tremaining: 38.4s\n","747:\tlearn: 0.3900188\ttotal: 1m 53s\tremaining: 38.3s\n","748:\tlearn: 0.3900136\ttotal: 1m 53s\tremaining: 38.1s\n","749:\tlearn: 0.3900064\ttotal: 1m 53s\tremaining: 37.9s\n","750:\tlearn: 0.3900014\ttotal: 1m 53s\tremaining: 37.8s\n","751:\tlearn: 0.3899962\ttotal: 1m 54s\tremaining: 37.6s\n","752:\tlearn: 0.3899888\ttotal: 1m 54s\tremaining: 37.5s\n","753:\tlearn: 0.3899813\ttotal: 1m 54s\tremaining: 37.3s\n","754:\tlearn: 0.3899704\ttotal: 1m 54s\tremaining: 37.2s\n","755:\tlearn: 0.3899616\ttotal: 1m 54s\tremaining: 37s\n","756:\tlearn: 0.3899544\ttotal: 1m 54s\tremaining: 36.9s\n","757:\tlearn: 0.3899497\ttotal: 1m 55s\tremaining: 36.7s\n","758:\tlearn: 0.3899439\ttotal: 1m 55s\tremaining: 36.6s\n","759:\tlearn: 0.3899373\ttotal: 1m 55s\tremaining: 36.4s\n","760:\tlearn: 0.3899298\ttotal: 1m 55s\tremaining: 36.3s\n","761:\tlearn: 0.3899235\ttotal: 1m 55s\tremaining: 36.1s\n","762:\tlearn: 0.3899152\ttotal: 1m 55s\tremaining: 36s\n","763:\tlearn: 0.3899113\ttotal: 1m 55s\tremaining: 35.8s\n","764:\tlearn: 0.3899078\ttotal: 1m 56s\tremaining: 35.7s\n","765:\tlearn: 0.3899004\ttotal: 1m 56s\tremaining: 35.5s\n","766:\tlearn: 0.3898876\ttotal: 1m 56s\tremaining: 35.3s\n","767:\tlearn: 0.3898815\ttotal: 1m 56s\tremaining: 35.2s\n","768:\tlearn: 0.3898678\ttotal: 1m 56s\tremaining: 35s\n","769:\tlearn: 0.3898565\ttotal: 1m 56s\tremaining: 34.9s\n","770:\tlearn: 0.3898481\ttotal: 1m 56s\tremaining: 34.7s\n","771:\tlearn: 0.3898338\ttotal: 1m 57s\tremaining: 34.6s\n","772:\tlearn: 0.3898238\ttotal: 1m 57s\tremaining: 34.4s\n","773:\tlearn: 0.3898163\ttotal: 1m 57s\tremaining: 34.3s\n","774:\tlearn: 0.3898059\ttotal: 1m 57s\tremaining: 34.1s\n","775:\tlearn: 0.3898019\ttotal: 1m 57s\tremaining: 34s\n","776:\tlearn: 0.3897930\ttotal: 1m 57s\tremaining: 33.8s\n","777:\tlearn: 0.3897855\ttotal: 1m 58s\tremaining: 33.7s\n","778:\tlearn: 0.3897793\ttotal: 1m 58s\tremaining: 33.5s\n","779:\tlearn: 0.3897716\ttotal: 1m 58s\tremaining: 33.4s\n","780:\tlearn: 0.3897625\ttotal: 1m 58s\tremaining: 33.2s\n","781:\tlearn: 0.3897546\ttotal: 1m 58s\tremaining: 33.1s\n","782:\tlearn: 0.3897495\ttotal: 1m 58s\tremaining: 32.9s\n","783:\tlearn: 0.3897422\ttotal: 1m 58s\tremaining: 32.8s\n","784:\tlearn: 0.3897394\ttotal: 1m 59s\tremaining: 32.6s\n","785:\tlearn: 0.3897334\ttotal: 1m 59s\tremaining: 32.5s\n","786:\tlearn: 0.3897266\ttotal: 1m 59s\tremaining: 32.3s\n","787:\tlearn: 0.3897178\ttotal: 1m 59s\tremaining: 32.2s\n","788:\tlearn: 0.3897122\ttotal: 1m 59s\tremaining: 32s\n","789:\tlearn: 0.3897042\ttotal: 1m 59s\tremaining: 31.8s\n","790:\tlearn: 0.3896981\ttotal: 1m 59s\tremaining: 31.7s\n","791:\tlearn: 0.3896911\ttotal: 2m\tremaining: 31.5s\n","792:\tlearn: 0.3896845\ttotal: 2m\tremaining: 31.4s\n","793:\tlearn: 0.3896807\ttotal: 2m\tremaining: 31.2s\n","794:\tlearn: 0.3896751\ttotal: 2m\tremaining: 31.1s\n","795:\tlearn: 0.3896671\ttotal: 2m\tremaining: 30.9s\n","796:\tlearn: 0.3896603\ttotal: 2m\tremaining: 30.8s\n","797:\tlearn: 0.3896511\ttotal: 2m\tremaining: 30.6s\n","798:\tlearn: 0.3896467\ttotal: 2m 1s\tremaining: 30.5s\n","799:\tlearn: 0.3896373\ttotal: 2m 1s\tremaining: 30.3s\n","800:\tlearn: 0.3896290\ttotal: 2m 1s\tremaining: 30.2s\n","801:\tlearn: 0.3896221\ttotal: 2m 1s\tremaining: 30s\n","802:\tlearn: 0.3896142\ttotal: 2m 1s\tremaining: 29.9s\n","803:\tlearn: 0.3896072\ttotal: 2m 1s\tremaining: 29.7s\n","804:\tlearn: 0.3895980\ttotal: 2m 1s\tremaining: 29.6s\n","805:\tlearn: 0.3895882\ttotal: 2m 2s\tremaining: 29.4s\n","806:\tlearn: 0.3895810\ttotal: 2m 2s\tremaining: 29.3s\n","807:\tlearn: 0.3895750\ttotal: 2m 2s\tremaining: 29.1s\n","808:\tlearn: 0.3895675\ttotal: 2m 2s\tremaining: 28.9s\n","809:\tlearn: 0.3895621\ttotal: 2m 2s\tremaining: 28.8s\n","810:\tlearn: 0.3895537\ttotal: 2m 2s\tremaining: 28.6s\n","811:\tlearn: 0.3895475\ttotal: 2m 3s\tremaining: 28.5s\n","812:\tlearn: 0.3895431\ttotal: 2m 3s\tremaining: 28.3s\n","813:\tlearn: 0.3895370\ttotal: 2m 3s\tremaining: 28.2s\n","814:\tlearn: 0.3895316\ttotal: 2m 3s\tremaining: 28s\n","815:\tlearn: 0.3895260\ttotal: 2m 3s\tremaining: 27.9s\n","816:\tlearn: 0.3895204\ttotal: 2m 3s\tremaining: 27.7s\n","817:\tlearn: 0.3895125\ttotal: 2m 3s\tremaining: 27.6s\n","818:\tlearn: 0.3895061\ttotal: 2m 4s\tremaining: 27.4s\n","819:\tlearn: 0.3894957\ttotal: 2m 4s\tremaining: 27.3s\n","820:\tlearn: 0.3894897\ttotal: 2m 4s\tremaining: 27.1s\n","821:\tlearn: 0.3894858\ttotal: 2m 4s\tremaining: 27s\n","822:\tlearn: 0.3894816\ttotal: 2m 4s\tremaining: 26.8s\n","823:\tlearn: 0.3894741\ttotal: 2m 4s\tremaining: 26.7s\n","824:\tlearn: 0.3894669\ttotal: 2m 5s\tremaining: 26.5s\n","825:\tlearn: 0.3894606\ttotal: 2m 5s\tremaining: 26.4s\n","826:\tlearn: 0.3894508\ttotal: 2m 5s\tremaining: 26.2s\n","827:\tlearn: 0.3894417\ttotal: 2m 5s\tremaining: 26.1s\n","828:\tlearn: 0.3894343\ttotal: 2m 5s\tremaining: 25.9s\n","829:\tlearn: 0.3894306\ttotal: 2m 5s\tremaining: 25.8s\n","830:\tlearn: 0.3894184\ttotal: 2m 5s\tremaining: 25.6s\n","831:\tlearn: 0.3894087\ttotal: 2m 6s\tremaining: 25.5s\n","832:\tlearn: 0.3894064\ttotal: 2m 6s\tremaining: 25.3s\n","833:\tlearn: 0.3893980\ttotal: 2m 6s\tremaining: 25.2s\n","834:\tlearn: 0.3893945\ttotal: 2m 6s\tremaining: 25s\n","835:\tlearn: 0.3893890\ttotal: 2m 6s\tremaining: 24.9s\n","836:\tlearn: 0.3893865\ttotal: 2m 6s\tremaining: 24.7s\n","837:\tlearn: 0.3893806\ttotal: 2m 6s\tremaining: 24.5s\n","838:\tlearn: 0.3893741\ttotal: 2m 7s\tremaining: 24.4s\n","839:\tlearn: 0.3893667\ttotal: 2m 7s\tremaining: 24.2s\n","840:\tlearn: 0.3893608\ttotal: 2m 7s\tremaining: 24.1s\n","841:\tlearn: 0.3893548\ttotal: 2m 7s\tremaining: 23.9s\n","842:\tlearn: 0.3893512\ttotal: 2m 7s\tremaining: 23.8s\n","843:\tlearn: 0.3893428\ttotal: 2m 7s\tremaining: 23.6s\n","844:\tlearn: 0.3893344\ttotal: 2m 8s\tremaining: 23.5s\n","845:\tlearn: 0.3893266\ttotal: 2m 8s\tremaining: 23.3s\n","846:\tlearn: 0.3893172\ttotal: 2m 8s\tremaining: 23.2s\n","847:\tlearn: 0.3893141\ttotal: 2m 8s\tremaining: 23s\n","848:\tlearn: 0.3893035\ttotal: 2m 8s\tremaining: 22.9s\n","849:\tlearn: 0.3892961\ttotal: 2m 8s\tremaining: 22.7s\n","850:\tlearn: 0.3892893\ttotal: 2m 9s\tremaining: 22.6s\n","851:\tlearn: 0.3892828\ttotal: 2m 9s\tremaining: 22.4s\n","852:\tlearn: 0.3892741\ttotal: 2m 9s\tremaining: 22.3s\n","853:\tlearn: 0.3892681\ttotal: 2m 9s\tremaining: 22.1s\n","854:\tlearn: 0.3892644\ttotal: 2m 9s\tremaining: 22s\n","855:\tlearn: 0.3892599\ttotal: 2m 9s\tremaining: 21.8s\n","856:\tlearn: 0.3892538\ttotal: 2m 9s\tremaining: 21.7s\n","857:\tlearn: 0.3892466\ttotal: 2m 10s\tremaining: 21.5s\n","858:\tlearn: 0.3892418\ttotal: 2m 10s\tremaining: 21.4s\n","859:\tlearn: 0.3892317\ttotal: 2m 10s\tremaining: 21.2s\n","860:\tlearn: 0.3892267\ttotal: 2m 10s\tremaining: 21.1s\n","861:\tlearn: 0.3892215\ttotal: 2m 10s\tremaining: 20.9s\n","862:\tlearn: 0.3892087\ttotal: 2m 10s\tremaining: 20.8s\n","863:\tlearn: 0.3891965\ttotal: 2m 10s\tremaining: 20.6s\n","864:\tlearn: 0.3891884\ttotal: 2m 11s\tremaining: 20.5s\n","865:\tlearn: 0.3891842\ttotal: 2m 11s\tremaining: 20.3s\n","866:\tlearn: 0.3891763\ttotal: 2m 11s\tremaining: 20.2s\n","867:\tlearn: 0.3891671\ttotal: 2m 11s\tremaining: 20s\n","868:\tlearn: 0.3891578\ttotal: 2m 11s\tremaining: 19.8s\n","869:\tlearn: 0.3891505\ttotal: 2m 11s\tremaining: 19.7s\n","870:\tlearn: 0.3891442\ttotal: 2m 11s\tremaining: 19.5s\n","871:\tlearn: 0.3891375\ttotal: 2m 12s\tremaining: 19.4s\n","872:\tlearn: 0.3891313\ttotal: 2m 12s\tremaining: 19.2s\n","873:\tlearn: 0.3891220\ttotal: 2m 12s\tremaining: 19.1s\n","874:\tlearn: 0.3891169\ttotal: 2m 12s\tremaining: 18.9s\n","875:\tlearn: 0.3891111\ttotal: 2m 12s\tremaining: 18.8s\n","876:\tlearn: 0.3891065\ttotal: 2m 12s\tremaining: 18.6s\n","877:\tlearn: 0.3890980\ttotal: 2m 12s\tremaining: 18.5s\n","878:\tlearn: 0.3890916\ttotal: 2m 13s\tremaining: 18.3s\n","879:\tlearn: 0.3890858\ttotal: 2m 13s\tremaining: 18.2s\n","880:\tlearn: 0.3890779\ttotal: 2m 13s\tremaining: 18s\n","881:\tlearn: 0.3890732\ttotal: 2m 13s\tremaining: 17.9s\n","882:\tlearn: 0.3890689\ttotal: 2m 13s\tremaining: 17.7s\n","883:\tlearn: 0.3890617\ttotal: 2m 13s\tremaining: 17.6s\n","884:\tlearn: 0.3890584\ttotal: 2m 13s\tremaining: 17.4s\n","885:\tlearn: 0.3890508\ttotal: 2m 14s\tremaining: 17.3s\n","886:\tlearn: 0.3890424\ttotal: 2m 14s\tremaining: 17.1s\n","887:\tlearn: 0.3890349\ttotal: 2m 14s\tremaining: 17s\n","888:\tlearn: 0.3890301\ttotal: 2m 14s\tremaining: 16.8s\n","889:\tlearn: 0.3890197\ttotal: 2m 14s\tremaining: 16.7s\n","890:\tlearn: 0.3890157\ttotal: 2m 14s\tremaining: 16.5s\n","891:\tlearn: 0.3890090\ttotal: 2m 15s\tremaining: 16.4s\n","892:\tlearn: 0.3889998\ttotal: 2m 15s\tremaining: 16.2s\n","893:\tlearn: 0.3889914\ttotal: 2m 15s\tremaining: 16.1s\n","894:\tlearn: 0.3889870\ttotal: 2m 15s\tremaining: 15.9s\n","895:\tlearn: 0.3889806\ttotal: 2m 15s\tremaining: 15.7s\n","896:\tlearn: 0.3889747\ttotal: 2m 15s\tremaining: 15.6s\n","897:\tlearn: 0.3889717\ttotal: 2m 16s\tremaining: 15.5s\n","898:\tlearn: 0.3889684\ttotal: 2m 16s\tremaining: 15.3s\n","899:\tlearn: 0.3889600\ttotal: 2m 16s\tremaining: 15.1s\n","900:\tlearn: 0.3889534\ttotal: 2m 16s\tremaining: 15s\n","901:\tlearn: 0.3889458\ttotal: 2m 16s\tremaining: 14.8s\n","902:\tlearn: 0.3889378\ttotal: 2m 16s\tremaining: 14.7s\n","903:\tlearn: 0.3889317\ttotal: 2m 17s\tremaining: 14.5s\n","904:\tlearn: 0.3889284\ttotal: 2m 17s\tremaining: 14.4s\n","905:\tlearn: 0.3889220\ttotal: 2m 17s\tremaining: 14.2s\n","906:\tlearn: 0.3889146\ttotal: 2m 17s\tremaining: 14.1s\n","907:\tlearn: 0.3889066\ttotal: 2m 17s\tremaining: 13.9s\n","908:\tlearn: 0.3889011\ttotal: 2m 17s\tremaining: 13.8s\n","909:\tlearn: 0.3888965\ttotal: 2m 17s\tremaining: 13.6s\n","910:\tlearn: 0.3888875\ttotal: 2m 18s\tremaining: 13.5s\n","911:\tlearn: 0.3888813\ttotal: 2m 18s\tremaining: 13.3s\n","912:\tlearn: 0.3888745\ttotal: 2m 18s\tremaining: 13.2s\n","913:\tlearn: 0.3888702\ttotal: 2m 18s\tremaining: 13s\n","914:\tlearn: 0.3888638\ttotal: 2m 18s\tremaining: 12.9s\n","915:\tlearn: 0.3888576\ttotal: 2m 18s\tremaining: 12.7s\n","916:\tlearn: 0.3888500\ttotal: 2m 19s\tremaining: 12.6s\n","917:\tlearn: 0.3888461\ttotal: 2m 19s\tremaining: 12.4s\n","918:\tlearn: 0.3888380\ttotal: 2m 19s\tremaining: 12.3s\n","919:\tlearn: 0.3888345\ttotal: 2m 19s\tremaining: 12.1s\n","920:\tlearn: 0.3888267\ttotal: 2m 19s\tremaining: 12s\n","921:\tlearn: 0.3888203\ttotal: 2m 19s\tremaining: 11.8s\n","922:\tlearn: 0.3888153\ttotal: 2m 20s\tremaining: 11.7s\n","923:\tlearn: 0.3888082\ttotal: 2m 20s\tremaining: 11.5s\n","924:\tlearn: 0.3888024\ttotal: 2m 20s\tremaining: 11.4s\n","925:\tlearn: 0.3887957\ttotal: 2m 20s\tremaining: 11.2s\n","926:\tlearn: 0.3887889\ttotal: 2m 20s\tremaining: 11.1s\n","927:\tlearn: 0.3887839\ttotal: 2m 20s\tremaining: 10.9s\n","928:\tlearn: 0.3887756\ttotal: 2m 20s\tremaining: 10.8s\n","929:\tlearn: 0.3887662\ttotal: 2m 21s\tremaining: 10.6s\n","930:\tlearn: 0.3887589\ttotal: 2m 21s\tremaining: 10.5s\n","931:\tlearn: 0.3887551\ttotal: 2m 21s\tremaining: 10.3s\n","932:\tlearn: 0.3887495\ttotal: 2m 21s\tremaining: 10.2s\n","933:\tlearn: 0.3887442\ttotal: 2m 21s\tremaining: 10s\n","934:\tlearn: 0.3887386\ttotal: 2m 21s\tremaining: 9.86s\n","935:\tlearn: 0.3887320\ttotal: 2m 21s\tremaining: 9.71s\n","936:\tlearn: 0.3887230\ttotal: 2m 22s\tremaining: 9.55s\n","937:\tlearn: 0.3887096\ttotal: 2m 22s\tremaining: 9.4s\n","938:\tlearn: 0.3886997\ttotal: 2m 22s\tremaining: 9.25s\n","939:\tlearn: 0.3886928\ttotal: 2m 22s\tremaining: 9.1s\n","940:\tlearn: 0.3886863\ttotal: 2m 22s\tremaining: 8.95s\n","941:\tlearn: 0.3886824\ttotal: 2m 22s\tremaining: 8.79s\n","942:\tlearn: 0.3886821\ttotal: 2m 22s\tremaining: 8.64s\n","943:\tlearn: 0.3886732\ttotal: 2m 23s\tremaining: 8.49s\n","944:\tlearn: 0.3886698\ttotal: 2m 23s\tremaining: 8.34s\n","945:\tlearn: 0.3886598\ttotal: 2m 23s\tremaining: 8.19s\n","946:\tlearn: 0.3886573\ttotal: 2m 23s\tremaining: 8.03s\n","947:\tlearn: 0.3886533\ttotal: 2m 23s\tremaining: 7.88s\n","948:\tlearn: 0.3886476\ttotal: 2m 23s\tremaining: 7.73s\n","949:\tlearn: 0.3886426\ttotal: 2m 23s\tremaining: 7.58s\n","950:\tlearn: 0.3886383\ttotal: 2m 24s\tremaining: 7.42s\n","951:\tlearn: 0.3886336\ttotal: 2m 24s\tremaining: 7.27s\n","952:\tlearn: 0.3886305\ttotal: 2m 24s\tremaining: 7.12s\n","953:\tlearn: 0.3886237\ttotal: 2m 24s\tremaining: 6.97s\n","954:\tlearn: 0.3886169\ttotal: 2m 24s\tremaining: 6.82s\n","955:\tlearn: 0.3886094\ttotal: 2m 24s\tremaining: 6.66s\n","956:\tlearn: 0.3886048\ttotal: 2m 24s\tremaining: 6.51s\n","957:\tlearn: 0.3885962\ttotal: 2m 25s\tremaining: 6.36s\n","958:\tlearn: 0.3885899\ttotal: 2m 25s\tremaining: 6.21s\n","959:\tlearn: 0.3885828\ttotal: 2m 25s\tremaining: 6.06s\n","960:\tlearn: 0.3885714\ttotal: 2m 25s\tremaining: 5.91s\n","961:\tlearn: 0.3885631\ttotal: 2m 25s\tremaining: 5.75s\n","962:\tlearn: 0.3885602\ttotal: 2m 25s\tremaining: 5.6s\n","963:\tlearn: 0.3885524\ttotal: 2m 25s\tremaining: 5.45s\n","964:\tlearn: 0.3885444\ttotal: 2m 26s\tremaining: 5.3s\n","965:\tlearn: 0.3885380\ttotal: 2m 26s\tremaining: 5.15s\n","966:\tlearn: 0.3885314\ttotal: 2m 26s\tremaining: 5s\n","967:\tlearn: 0.3885206\ttotal: 2m 26s\tremaining: 4.85s\n","968:\tlearn: 0.3885164\ttotal: 2m 26s\tremaining: 4.7s\n","969:\tlearn: 0.3885131\ttotal: 2m 26s\tremaining: 4.54s\n","970:\tlearn: 0.3885060\ttotal: 2m 27s\tremaining: 4.39s\n","971:\tlearn: 0.3884987\ttotal: 2m 27s\tremaining: 4.24s\n","972:\tlearn: 0.3884975\ttotal: 2m 27s\tremaining: 4.09s\n","973:\tlearn: 0.3884895\ttotal: 2m 27s\tremaining: 3.94s\n","974:\tlearn: 0.3884794\ttotal: 2m 27s\tremaining: 3.79s\n","975:\tlearn: 0.3884728\ttotal: 2m 27s\tremaining: 3.63s\n","976:\tlearn: 0.3884665\ttotal: 2m 28s\tremaining: 3.48s\n","977:\tlearn: 0.3884604\ttotal: 2m 28s\tremaining: 3.33s\n","978:\tlearn: 0.3884528\ttotal: 2m 28s\tremaining: 3.18s\n","979:\tlearn: 0.3884458\ttotal: 2m 28s\tremaining: 3.03s\n","980:\tlearn: 0.3884415\ttotal: 2m 28s\tremaining: 2.88s\n","981:\tlearn: 0.3884362\ttotal: 2m 28s\tremaining: 2.73s\n","982:\tlearn: 0.3884200\ttotal: 2m 29s\tremaining: 2.58s\n","983:\tlearn: 0.3884146\ttotal: 2m 29s\tremaining: 2.42s\n","984:\tlearn: 0.3884111\ttotal: 2m 29s\tremaining: 2.27s\n","985:\tlearn: 0.3884038\ttotal: 2m 29s\tremaining: 2.12s\n","986:\tlearn: 0.3883951\ttotal: 2m 29s\tremaining: 1.97s\n","987:\tlearn: 0.3883894\ttotal: 2m 29s\tremaining: 1.82s\n","988:\tlearn: 0.3883833\ttotal: 2m 29s\tremaining: 1.67s\n","989:\tlearn: 0.3883764\ttotal: 2m 30s\tremaining: 1.51s\n","990:\tlearn: 0.3883713\ttotal: 2m 30s\tremaining: 1.36s\n","991:\tlearn: 0.3883661\ttotal: 2m 30s\tremaining: 1.21s\n","992:\tlearn: 0.3883634\ttotal: 2m 30s\tremaining: 1.06s\n","993:\tlearn: 0.3883567\ttotal: 2m 30s\tremaining: 909ms\n","994:\tlearn: 0.3883500\ttotal: 2m 30s\tremaining: 758ms\n","995:\tlearn: 0.3883445\ttotal: 2m 30s\tremaining: 606ms\n","996:\tlearn: 0.3883404\ttotal: 2m 31s\tremaining: 455ms\n","997:\tlearn: 0.3883339\ttotal: 2m 31s\tremaining: 303ms\n","998:\tlearn: 0.3883282\ttotal: 2m 31s\tremaining: 152ms\n","999:\tlearn: 0.3883213\ttotal: 2m 31s\tremaining: 0us\n","log loss of CATBoost is:  [0.30525369 0.11578143 0.16714848 ... 0.11577026 0.13440415 0.34546207]\n"]}],"source":["CBC_test = CatBoostClassifier() # use default params\n","CBC_test = CBC_test.fit(X_final,y)\n","pred_Cat = CBC_test.predict_proba(X_test)[:,1]\n"]},{"cell_type":"code","execution_count":90,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["log loss of CATBoost is:  0.39311635972273495\n"]}],"source":["print('log loss of CATBoost is: ', str(log_loss(y_test,pred_Cat)))"]},{"cell_type":"markdown","metadata":{},"source":["################################### Logistic Regression #######################################"]},{"cell_type":"code","execution_count":76,"metadata":{},"outputs":[],"source":["# Standardize the data\n","col = ['hour','weekday']\n","X_sc = scale_num_var(X_final, col) # transform training dataset\n","testDF_sc = scale_num_var(testDF_final, col) # transform test dataset\n","\n","X_final_sc = drop_dup_colname(X_sc)\n","testDF_final_sc = drop_dup_colname(testDF_sc)\n"]},{"cell_type":"code","execution_count":77,"metadata":{},"outputs":[],"source":["X_train_sc, X_test_sc,y_train_sc, y_test_sc = train_test_split(X_final_sc,y,test_size=0.3,random_state=42) # split this part of data to train and test data"]},{"cell_type":"code","execution_count":78,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/Users/nigelsimida/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n"]},{"data":{"text/plain":["0.4304583977541348"]},"execution_count":78,"metadata":{},"output_type":"execute_result"}],"source":["from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score, f1_score\n","\n","\n","lr = LogisticRegression(C=0.01, random_state=42, solver='lbfgs',penalty = 'l2') # build the logistic model\n","lr = lr.fit(X_train_sc,y_train_sc)\n","\n","pred_proba = lr.predict_proba(X_test_sc) # get the predicted probability\n","\n","# calculate loss\n","lr_loss = log_loss(y_test_sc,pred_proba[:,1])\n","lr_loss"]},{"cell_type":"markdown","metadata":{},"source":["###################################### Neural Network ######################################"]},{"cell_type":"code","execution_count":84,"metadata":{"id":"MRH6lih5H6yo","outputId":"28179d14-c661-46d8-bbb0-6a9d0411878c"},"outputs":[],"source":["NEpochs = 200\n","BatchSize= 1000\n","Optimizer=optimizers.RMSprop(learning_rate=0.001)"]},{"cell_type":"code","execution_count":82,"metadata":{"id":"5dL8esFLH6yo","outputId":"a6a98ed5-b9c7-467a-8b45-ee44a415a46a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense (Dense)               (None, 20)                1080      \n","                                                                 \n"," dense_1 (Dense)             (None, 15)                315       \n","                                                                 \n"," dense_2 (Dense)             (None, 10)                160       \n","                                                                 \n"," leaky_re_lu (LeakyReLU)     (None, 10)                0         \n","                                                                 \n"," dense_3 (Dense)             (None, 5)                 55        \n","                                                                 \n"," dense_4 (Dense)             (None, 1)                 6         \n","                                                                 \n","=================================================================\n","Total params: 1,616\n","Trainable params: 1,616\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n"]},{"name":"stderr","output_type":"stream","text":["2022-12-06 14:01:48.281163: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"]}],"source":["from keras.layers import LeakyReLU\n","SpiralNN = Sequential()\n","\n","SpiralNN.add(Dense(units=20,input_shape=(X_train_sc.shape[1],),activation=\"relu\",use_bias=True))\n","SpiralNN.add(Dense(units=15,activation=\"relu\",use_bias=True))\n","SpiralNN.add(Dense(units=10,use_bias=True))\n","SpiralNN.add(LeakyReLU(alpha=0.05))\n","SpiralNN.add(Dense(units=5,activation=\"relu\",use_bias=True))\n","SpiralNN.add(Dense(units=1,activation=\"sigmoid\",use_bias=True))\n","\n","SpiralNN.compile(loss='binary_crossentropy', optimizer=Optimizer,metrics=['binary_crossentropy','accuracy'])\n","print(SpiralNN.summary())"]},{"cell_type":"code","execution_count":85,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 1s 500ms/step\n","Number of Epochs = 200\n","Log loss: 0.41347576628246857\n"]}],"source":["#%% Fit NN Model\n","\n","from keras.callbacks import EarlyStopping\n","\n","\n","StopRule = EarlyStopping(monitor='binary_crossentropy',mode='min',verbose=0,patience=100,min_delta=0.0)\n","FitHist = SpiralNN.fit(X_train_sc,y_train_sc,\\\n","                    epochs=NEpochs,batch_size=BatchSize,verbose=0, \\\n","                    callbacks=[StopRule])\n","    \n","#FitHist = SpiralNN.fit(TrXrsc,TrColorCode,epochs=NEpochs,batch_size=BatchSize,verbose=0)\n","\n","TestP = SpiralNN.predict(X_test_sc,batch_size = X_train_sc.shape[0])\n","\n","print(\"Number of Epochs = \"+str(len(FitHist.history['accuracy'])))\n","print(\"Log loss: \"+str(log_loss(y_test_sc,TestP)))"]},{"cell_type":"markdown","metadata":{},"source":["# Compare Model Performance with Best Parameters & Predict Probability for Test Data"]},{"cell_type":"code","execution_count":86,"metadata":{},"outputs":[],"source":["from sklearn.metrics import log_loss"]},{"cell_type":"code","execution_count":51,"metadata":{},"outputs":[],"source":["val_test=[]\n","for i in [1,2,3,4,6,7,8,9,10]:\n","    X,y,testDF = get_X_y_test(i)\n","\n","\n","    X[columns] = X[columns].astype('category') # change the data type of categorical variables to category\n","\n","    X.columns = X.columns.astype(str) # change all column name to string\n","        \n","\n","    # rename duplicated col names\n","    X_final = drop_dup_colname(X) \n","    pred = CBC.predict_proba(X_final)[:,1]\n","    val_test.append(log_loss(y,pred))"]},{"cell_type":"code","execution_count":52,"metadata":{},"outputs":[{"data":{"text/plain":["[0.3857151160361722,\n"," 0.3854864480187115,\n"," 0.3850835088310268,\n"," 0.3855738207770144,\n"," 0.38580913894204016,\n"," 0.38505835398800164,\n"," 0.38580341039310306,\n"," 0.3860189855345325,\n"," 0.2784329163884995]"]},"execution_count":52,"metadata":{},"output_type":"execute_result"}],"source":["val_test"]},{"cell_type":"code","execution_count":48,"metadata":{},"outputs":[{"data":{"text/plain":["0.3857151160361722"]},"execution_count":48,"metadata":{},"output_type":"execute_result"}],"source":["log_loss(y,pred[:,1])"]},{"cell_type":"code","execution_count":54,"metadata":{},"outputs":[{"data":{"text/plain":["0.385929896129409"]},"execution_count":54,"metadata":{},"output_type":"execute_result"}],"source":["X,y,testDF = get_X_y_test(5)\n","\n","\n","X[columns] = X[columns].astype('category') # change the data type of categorical variables to category\n","\n","X.columns = X.columns.astype(str) # change all column name to string\n","    \n","\n","# rename duplicated col names\n","X_final = drop_dup_colname(X) \n","pred = CBC.predict_proba(X_final)[:,1]\n","log_loss(y,pred)"]},{"cell_type":"code","execution_count":94,"metadata":{},"outputs":[],"source":["def pred_test_fun(part,method):\n","    X,y,testDF = get_X_y_test(part)\n","\n","    columns = ['C1', 'banner_pos', 'site_id', 'site_domain', 'site_category',\n","    'app_id', 'app_domain', 'app_category', 'device_id', 'device_ip',\n","    'device_model', 'device_type', 'device_conn_type', 'C14', 'C15', 'C16',\n","    'C17', 'C18', 'C19', 'C20', 'C21']\n","\n","    if part <= 5: # if we took one part of the first five part of data, we take the 10th part of data as the validation data\n","        X_val,y_val,testDF_val = get_X_y_test(10)\n","    if part >5:\n","        X_val,y_val,testDF_val = get_X_y_test(1)\n","    X_val_final, testDF_val_final = freq_encode(X_val,testDF_val,columns, threshold=10) # Encode categorical variables with high cardinality\n","    X_val_final.columns = X_val_final.columns.astype(str)\n","    X_val_final = drop_dup_colname(X_val_final)\n","\n","    if method == 'CATboost':\n","        X,y,testDF = get_X_y_test(part)\n","\n","        X[columns] = X[columns].astype('category') # change the data type of categorical variables to category\n","\n","        X.columns = X.columns.astype(str) # change all column name to string\n","            \n","\n","        # rename duplicated col names\n","        X_final = drop_dup_colname(X) \n","        testDF_final = drop_dup_colname(testDF)\n","\n","        #X_train, X_test,y_train, y_test = train_test_split(X_final,y,test_size=0.3,random_state=42) # split this part of data to train and test data\n","\n","        CBC = CatBoostClassifier(cat_features=columns)\n","\n","\n","        parameters = {'depth'  : [10,15,20],\n","                      'learning_rate' : [0.02,0.1,0.3],\n","                      'iterations'    : [50,300],\n","                      'one_hot_max_size': [2,10,15]\n","                    }\n","\n","        Grid_CBC = GridSearchCV(estimator=CBC,scoring='neg_log_loss',param_grid = parameters, cv = 3, n_jobs=-1)\n","        Grid_CBC.fit(X_final, y)\n","\n","        #pred_test = Grid_CBC.predict(testDF_final)\n","\n","        logloss = log_loss(y_val,Grid_CBC.predict_proba(X_val_final))\n","        best_params_cat = Grid_CBC.best_params_\n","\n","        return Grid_CBC,best_params_cat,logloss\n","\n","        \n","\n","    if method == 'XGboost':\n","        X_final, testDF_final = freq_encode(X,testDF,columns, threshold=10) # Encode categorical variables with high cardinality\n","        X_final.columns = X_final.columns.astype(str)\n","            \n","\n","        # rename duplicated col names\n","        X_final = drop_dup_colname(X_final) \n","        testDF_final = drop_dup_colname(testDF_final)\n","\n","        # rename duplicated col names\n","        X_final = drop_dup_colname(X_final) \n","        testDF_final = drop_dup_colname(testDF_final)\n","\n","        \n","\n","        # get the Best_Parameter for xgboost\n","        Best_Parameter = xgboost_bp(X_final,y)\n","        \n","        xgbc0 = xgb.XGBClassifier(**Best_Parameter)\n","        xgbc = xgbc0.fit(X_final,y)\n","\n","        #pred_test = xgbc.predict_proba(testDF_final)[:,1]\n","        \n","        logloss = log_loss(y_val,xgbc.predict_proba(X_val_final)[:,1])\n","        return xgbc,Best_Parameter,logloss\n","\n","    if method =='logisitc_regression':\n","        X_final, testDF_final = freq_encode(X,testDF,columns, threshold=10) # Encode categorical variables with high cardinality\n","        X_final.columns = X_final.columns.astype(str)\n","\n","        # rename duplicated col names\n","        X_final = drop_dup_colname(X_final) \n","        testDF_final = drop_dup_colname(testDF_final)\n","\n","        # Standardize the data\n","        col = ['hour','weekday']\n","        X_final_sc = scale_num_var(X_final, col) # transform training dataset\n","        X_testDF_sc = scale_num_var(testDF_final, col) # transform test dataset\n","\n","        X_train_sc, X_test_sc,y_train_sc, y_test_sc = train_test_split(X_final_sc,y,test_size=0.3,random_state=42) # split this part of data to train and test data\n","        \n","        lr = LogisticRegression(C=0.01, random_state=42, solver='lbfgs',penalty = 'l2') # build the logistic model\n","        lr = lr.fit(X_final_sc,y)\n","\n","        #pred_test = lr.predict_proba(X_testDF_sc)\n","        logloss = log_loss(y_val,lr.predict_proba(X_val_final)[:,1])\n","        return lr,logloss\n","\n","    if method == 'neural_network':\n","        X_final, testDF_final = freq_encode(X,testDF,columns, threshold=10) # Encode categorical variables with high cardinality\n","        X_final.columns = X_final.columns.astype(str)\n","        \n","        # rename duplicated col names\n","        X_final = drop_dup_colname(X_final) \n","        testDF_final = drop_dup_colname(testDF_final)\n","\n","        # Standardize the data\n","        col = ['hour','weekday']\n","        X_final_sc = scale_num_var(X_final, col) # transform training dataset\n","        X_testDF_sc = scale_num_var(testDF_final, col) # transform test dataset\n","        X_train_sc, X_test_sc,y_train_sc, y_test_sc = train_test_split(X_final_sc,y,test_size=0.3,random_state=42) # split this part of data to train and test data\n","\n","        # get the output and NN model from the defined function\n","        SpiralNN = nn_model(250,400,optimizers.RMSprop(learning_rate=0.001),X_final_sc,y,X_testDF_sc)\n","\n","        logloss = log_loss(y_val,SpiralNN.predict(X_val_final,batch_size=X_final_sc.shape[0]))\n","        return SpiralNN,logloss"]},{"cell_type":"code","execution_count":92,"metadata":{},"outputs":[],"source":["part = 1 # Specify the first part of data to train the model"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 1s 809ms/step\n","1/1 [==============================] - 1s 578ms/step\n","0.4163898422347551\n"]}],"source":["# try 'XGboost','CATBoost','logisitc_regression' and 'neural_network' in the second arg, keep the one with lowest logloss,\n","# then write it out in next chunk of code\n","\n","NN_model,logloss = pred_test_fun(part,'neural_network')\n","print(logloss)"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\jwa2238\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n","  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n","C:\\Users\\jwa2238\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n","  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"]},{"name":"stdout","output_type":"stream","text":["Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\jwa2238\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n","  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n","C:\\Users\\jwa2238\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n","  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n","C:\\Users\\jwa2238\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n","  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n","C:\\Users\\jwa2238\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n","  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n","C:\\Users\\jwa2238\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n","  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n","C:\\Users\\jwa2238\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n","  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n","C:\\Users\\jwa2238\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n","  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n","C:\\Users\\jwa2238\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n","  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n","C:\\Users\\jwa2238\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n","  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n","C:\\Users\\jwa2238\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n","  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n","C:\\Users\\jwa2238\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n","  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n","C:\\Users\\jwa2238\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n","  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n","C:\\Users\\jwa2238\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n","  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n","C:\\Users\\jwa2238\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n","  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n","C:\\Users\\jwa2238\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n","  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n","C:\\Users\\jwa2238\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n","  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n","C:\\Users\\jwa2238\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n","  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n","C:\\Users\\jwa2238\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n","  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n","C:\\Users\\jwa2238\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n","  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n","C:\\Users\\jwa2238\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n","  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n","C:\\Users\\jwa2238\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n","  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n","C:\\Users\\jwa2238\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n","  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n","C:\\Users\\jwa2238\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n","  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n","C:\\Users\\jwa2238\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n","  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n","C:\\Users\\jwa2238\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n","  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n","C:\\Users\\jwa2238\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n","  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n","C:\\Users\\jwa2238\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n","  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n","C:\\Users\\jwa2238\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n","  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n","C:\\Users\\jwa2238\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n","  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n","C:\\Users\\jwa2238\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n","  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n","C:\\Users\\jwa2238\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n","  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n","C:\\Users\\jwa2238\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n","  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n","C:\\Users\\jwa2238\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n","  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n","C:\\Users\\jwa2238\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n","  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n","C:\\Users\\jwa2238\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n","  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n","C:\\Users\\jwa2238\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n","  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n","C:\\Users\\jwa2238\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n","  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n","C:\\Users\\jwa2238\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n","  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n","C:\\Users\\jwa2238\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n","  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n","C:\\Users\\jwa2238\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n","  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n","C:\\Users\\jwa2238\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n","  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n","C:\\Users\\jwa2238\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n","  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n","C:\\Users\\jwa2238\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n","  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n","C:\\Users\\jwa2238\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n","  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n","C:\\Users\\jwa2238\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n","  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n","C:\\Users\\jwa2238\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n","  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n","C:\\Users\\jwa2238\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n","  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n","C:\\Users\\jwa2238\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n","  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n","C:\\Users\\jwa2238\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n","  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n","C:\\Users\\jwa2238\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n","  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n","C:\\Users\\jwa2238\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n","  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n","C:\\Users\\jwa2238\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n","  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n","C:\\Users\\jwa2238\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n","  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n","C:\\Users\\jwa2238\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n","  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n","C:\\Users\\jwa2238\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n","  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n","C:\\Users\\jwa2238\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n","  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n","C:\\Users\\jwa2238\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n","  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n","C:\\Users\\jwa2238\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n","  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n","C:\\Users\\jwa2238\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n","  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n","C:\\Users\\jwa2238\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n","  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n","C:\\Users\\jwa2238\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n","  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n","C:\\Users\\jwa2238\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n","  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n","C:\\Users\\jwa2238\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n","  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n","C:\\Users\\jwa2238\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n","  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n","C:\\Users\\jwa2238\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n","  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n","C:\\Users\\jwa2238\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n","  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n","C:\\Users\\jwa2238\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n","  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n","C:\\Users\\jwa2238\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n","  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n","C:\\Users\\jwa2238\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n","  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n","C:\\Users\\jwa2238\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n","  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n","C:\\Users\\jwa2238\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n","  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n","C:\\Users\\jwa2238\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n","  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n","C:\\Users\\jwa2238\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n","  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n","C:\\Users\\jwa2238\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:2465: RuntimeWarning: divide by zero encountered in log\n","  loss = -(transformed_labels * np.log(y_pred)).sum(axis=1)\n","C:\\Users\\jwa2238\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:2465: RuntimeWarning: invalid value encountered in multiply\n","  loss = -(transformed_labels * np.log(y_pred)).sum(axis=1)\n","C:\\Users\\jwa2238\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:2465: RuntimeWarning: divide by zero encountered in log\n","  loss = -(transformed_labels * np.log(y_pred)).sum(axis=1)\n","C:\\Users\\jwa2238\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:2465: RuntimeWarning: invalid value encountered in multiply\n","  loss = -(transformed_labels * np.log(y_pred)).sum(axis=1)\n","C:\\Users\\jwa2238\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n","  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n","C:\\Users\\jwa2238\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n","  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n","C:\\Users\\jwa2238\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n","  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n","C:\\Users\\jwa2238\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n","  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n","C:\\Users\\jwa2238\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n","  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n","C:\\Users\\jwa2238\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n","  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n","C:\\Users\\jwa2238\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n","  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n","C:\\Users\\jwa2238\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n","  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n","C:\\Users\\jwa2238\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n","  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n","C:\\Users\\jwa2238\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n","  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n","C:\\Users\\jwa2238\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n","  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n","C:\\Users\\jwa2238\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n","  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n","C:\\Users\\jwa2238\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n","  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n","C:\\Users\\jwa2238\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n","  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n","C:\\Users\\jwa2238\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n","  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n","C:\\Users\\jwa2238\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n","  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n","C:\\Users\\jwa2238\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [        nan -0.39495135 -0.43906842 -0.39909737]\n","  warnings.warn(\n","C:\\Users\\jwa2238\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the train scores are non-finite: [        nan -0.38916683 -0.43860919 -0.39633453]\n","  warnings.warn(\n","C:\\Users\\jwa2238\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n","  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n","C:\\Users\\jwa2238\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n","  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n","C:\\Users\\jwa2238\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n","  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n","C:\\Users\\jwa2238\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n","  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n","C:\\Users\\jwa2238\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n","  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n","C:\\Users\\jwa2238\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n","  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n","C:\\Users\\jwa2238\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n","  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n","C:\\Users\\jwa2238\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n","  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n","C:\\Users\\jwa2238\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n","  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n","C:\\Users\\jwa2238\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n","  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n","C:\\Users\\jwa2238\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n","  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n","C:\\Users\\jwa2238\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n","  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n","C:\\Users\\jwa2238\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n","  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n","C:\\Users\\jwa2238\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n","  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n","C:\\Users\\jwa2238\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n","  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"]},{"name":"stdout","output_type":"stream","text":["0.39057681333350874\n"]}],"source":["XG_model,XG_bp,logloss_XG = pred_test_fun(part,'XGboost')\n","print(logloss_XG)"]},{"cell_type":"code","execution_count":95,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/Users/nigelsimida/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n"]},{"name":"stdout","output_type":"stream","text":["0.4451378281035794\n"]}],"source":["lr_model,logloss_lr = pred_test_fun(part,'logisitc_regression')\n","print(logloss_lr)"]},{"cell_type":"markdown","metadata":{},"source":["### Due to limited memory of my local PC and low efficiency of CATBoost, I implemented the function \"pred_test_fun(1,'CATBoost')\". The hyperparameter tuning process gives the best parameters for CATBoost as follows: bp_CAT = {'depth': 15,'learning_rate': 0.1,'iterations': 300,'one_hot_max_size': 10}, so I trained my CATBoost model with the given besst parameters"]},{"cell_type":"code","execution_count":97,"metadata":{},"outputs":[],"source":["columns = ['C1', 'banner_pos', 'site_id', 'site_domain', 'site_category',\n","    'app_id', 'app_domain', 'app_category', 'device_id', 'device_ip',\n","    'device_model', 'device_type', 'device_conn_type', 'C14', 'C15', 'C16',\n","    'C17', 'C18', 'C19', 'C20', 'C21']"]},{"cell_type":"code","execution_count":107,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/var/folders/m1/kt43_1vj58b_mx4h1rjqj0940000gn/T/ipykernel_40661/554052727.py:4: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  testDF_cat[columns] = testDF_cat[columns].astype('category')\n"]}],"source":["X,y_cat,testDF_cat = get_X_y_test(10)\n","\n","X[columns] = X[columns].astype('category') # change the data type of categorical variables to category\n","testDF_cat[columns] = testDF_cat[columns].astype('category')\n","testDF_cat.columns = testDF_cat.columns.astype(str)\n","X.columns = X.columns.astype(str) # change all column name to string\n","    \n","\n","# rename duplicated col names\n","X_final_cat = drop_dup_colname(X) "]},{"cell_type":"code","execution_count":139,"metadata":{},"outputs":[{"data":{"text/html":["<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=0.01, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=0.01, random_state=42)</pre></div></div></div></div></div>"],"text/plain":["LogisticRegression(C=0.01, random_state=42)"]},"execution_count":139,"metadata":{},"output_type":"execute_result"}],"source":["lr_model"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0:\tlearn: 0.6253151\ttotal: 9.95s\tremaining: 49m 33s\n","1:\tlearn: 0.5750125\ttotal: 18.9s\tremaining: 47m 3s\n","2:\tlearn: 0.5359508\ttotal: 29.2s\tremaining: 48m 9s\n","3:\tlearn: 0.5064213\ttotal: 37.4s\tremaining: 46m 7s\n","4:\tlearn: 0.4826467\ttotal: 47.9s\tremaining: 47m 5s\n","5:\tlearn: 0.4651778\ttotal: 57.6s\tremaining: 47m 3s\n","6:\tlearn: 0.4510872\ttotal: 1m 7s\tremaining: 47m 11s\n","7:\tlearn: 0.4404649\ttotal: 1m 17s\tremaining: 46m 52s\n","8:\tlearn: 0.4322554\ttotal: 1m 26s\tremaining: 46m 43s\n","9:\tlearn: 0.4258370\ttotal: 1m 36s\tremaining: 46m 24s\n","10:\tlearn: 0.4204279\ttotal: 1m 45s\tremaining: 46m 24s\n","11:\tlearn: 0.4161623\ttotal: 1m 57s\tremaining: 47m 5s\n","12:\tlearn: 0.4126620\ttotal: 2m 8s\tremaining: 47m 15s\n","13:\tlearn: 0.4095667\ttotal: 2m 20s\tremaining: 47m 43s\n","14:\tlearn: 0.4075348\ttotal: 2m 30s\tremaining: 47m 48s\n","15:\tlearn: 0.4055649\ttotal: 2m 42s\tremaining: 47m 59s\n","16:\tlearn: 0.4038016\ttotal: 2m 53s\tremaining: 48m 13s\n","17:\tlearn: 0.4022784\ttotal: 3m 3s\tremaining: 47m 47s\n","18:\tlearn: 0.4013000\ttotal: 3m 15s\tremaining: 48m 10s\n","19:\tlearn: 0.3999565\ttotal: 3m 26s\tremaining: 48m 8s\n","20:\tlearn: 0.3989881\ttotal: 3m 37s\tremaining: 48m 4s\n","21:\tlearn: 0.3982240\ttotal: 3m 49s\tremaining: 48m 15s\n","22:\tlearn: 0.3973524\ttotal: 4m 1s\tremaining: 48m 30s\n","23:\tlearn: 0.3965236\ttotal: 4m 13s\tremaining: 48m 35s\n","24:\tlearn: 0.3958828\ttotal: 4m 25s\tremaining: 48m 36s\n","25:\tlearn: 0.3951415\ttotal: 4m 35s\tremaining: 48m 24s\n","26:\tlearn: 0.3945770\ttotal: 4m 46s\tremaining: 48m 12s\n","27:\tlearn: 0.3937436\ttotal: 4m 58s\tremaining: 48m 21s\n","28:\tlearn: 0.3932829\ttotal: 5m 9s\tremaining: 48m 12s\n","29:\tlearn: 0.3926340\ttotal: 5m 22s\tremaining: 48m 23s\n","30:\tlearn: 0.3922353\ttotal: 5m 33s\tremaining: 48m 12s\n","31:\tlearn: 0.3916551\ttotal: 5m 45s\tremaining: 48m 16s\n","32:\tlearn: 0.3912604\ttotal: 5m 56s\tremaining: 48m 2s\n","33:\tlearn: 0.3907081\ttotal: 6m 8s\tremaining: 48m 2s\n","34:\tlearn: 0.3903303\ttotal: 6m 18s\tremaining: 47m 48s\n","35:\tlearn: 0.3899031\ttotal: 6m 28s\tremaining: 47m 30s\n","36:\tlearn: 0.3895394\ttotal: 6m 40s\tremaining: 47m 25s\n","37:\tlearn: 0.3891732\ttotal: 6m 53s\tremaining: 47m 31s\n","38:\tlearn: 0.3888158\ttotal: 7m 8s\tremaining: 47m 44s\n","39:\tlearn: 0.3884560\ttotal: 7m 23s\tremaining: 48m 1s\n","40:\tlearn: 0.3880037\ttotal: 7m 37s\tremaining: 48m 12s\n","41:\tlearn: 0.3876290\ttotal: 7m 54s\tremaining: 48m 35s\n","42:\tlearn: 0.3873678\ttotal: 8m 7s\tremaining: 48m 35s\n","43:\tlearn: 0.3870415\ttotal: 8m 22s\tremaining: 48m 42s\n","44:\tlearn: 0.3867609\ttotal: 8m 37s\tremaining: 48m 51s\n","45:\tlearn: 0.3864690\ttotal: 8m 50s\tremaining: 48m 50s\n","46:\tlearn: 0.3861460\ttotal: 9m 4s\tremaining: 48m 50s\n","47:\tlearn: 0.3859483\ttotal: 9m 17s\tremaining: 48m 44s\n","48:\tlearn: 0.3857137\ttotal: 9m 31s\tremaining: 48m 48s\n","49:\tlearn: 0.3855540\ttotal: 9m 47s\tremaining: 48m 57s\n","50:\tlearn: 0.3852801\ttotal: 9m 59s\tremaining: 48m 46s\n","51:\tlearn: 0.3850678\ttotal: 10m 15s\tremaining: 48m 54s\n","52:\tlearn: 0.3849460\ttotal: 10m 26s\tremaining: 48m 42s\n","53:\tlearn: 0.3846673\ttotal: 10m 45s\tremaining: 48m 59s\n","54:\tlearn: 0.3844839\ttotal: 10m 58s\tremaining: 48m 52s\n","55:\tlearn: 0.3843055\ttotal: 11m 10s\tremaining: 48m 41s\n","56:\tlearn: 0.3840559\ttotal: 11m 21s\tremaining: 48m 24s\n","57:\tlearn: 0.3839265\ttotal: 11m 33s\tremaining: 48m 13s\n","58:\tlearn: 0.3834733\ttotal: 11m 47s\tremaining: 48m 10s\n","59:\tlearn: 0.3833442\ttotal: 11m 58s\tremaining: 47m 55s\n","60:\tlearn: 0.3830296\ttotal: 12m 11s\tremaining: 47m 46s\n","61:\tlearn: 0.3828625\ttotal: 12m 23s\tremaining: 47m 35s\n","62:\tlearn: 0.3825753\ttotal: 12m 38s\tremaining: 47m 31s\n","63:\tlearn: 0.3823560\ttotal: 12m 49s\tremaining: 47m 16s\n","64:\tlearn: 0.3821763\ttotal: 13m 1s\tremaining: 47m 4s\n","65:\tlearn: 0.3819155\ttotal: 13m 14s\tremaining: 46m 55s\n","66:\tlearn: 0.3818505\ttotal: 13m 27s\tremaining: 46m 47s\n","67:\tlearn: 0.3817103\ttotal: 13m 38s\tremaining: 46m 32s\n","68:\tlearn: 0.3815700\ttotal: 13m 51s\tremaining: 46m 22s\n","69:\tlearn: 0.3815595\ttotal: 13m 53s\tremaining: 45m 37s\n","70:\tlearn: 0.3813436\ttotal: 14m 5s\tremaining: 45m 25s\n","71:\tlearn: 0.3812230\ttotal: 14m 16s\tremaining: 45m 12s\n","72:\tlearn: 0.3809561\ttotal: 14m 28s\tremaining: 45m\n","73:\tlearn: 0.3807897\ttotal: 14m 44s\tremaining: 45m\n","74:\tlearn: 0.3805594\ttotal: 14m 57s\tremaining: 44m 52s\n","75:\tlearn: 0.3803809\ttotal: 15m 8s\tremaining: 44m 38s\n","76:\tlearn: 0.3802071\ttotal: 15m 26s\tremaining: 44m 43s\n","77:\tlearn: 0.3799968\ttotal: 15m 40s\tremaining: 44m 36s\n","78:\tlearn: 0.3799419\ttotal: 15m 52s\tremaining: 44m 25s\n","79:\tlearn: 0.3798339\ttotal: 16m 9s\tremaining: 44m 26s\n","80:\tlearn: 0.3795127\ttotal: 16m 23s\tremaining: 44m 20s\n","81:\tlearn: 0.3793511\ttotal: 16m 42s\tremaining: 44m 25s\n","82:\tlearn: 0.3792697\ttotal: 16m 57s\tremaining: 44m 20s\n","83:\tlearn: 0.3791072\ttotal: 17m 12s\tremaining: 44m 15s\n","84:\tlearn: 0.3788005\ttotal: 17m 27s\tremaining: 44m 8s\n","85:\tlearn: 0.3787009\ttotal: 17m 39s\tremaining: 43m 56s\n","86:\tlearn: 0.3785323\ttotal: 17m 49s\tremaining: 43m 38s\n","87:\tlearn: 0.3784439\ttotal: 18m 3s\tremaining: 43m 30s\n","88:\tlearn: 0.3783244\ttotal: 18m 15s\tremaining: 43m 16s\n","89:\tlearn: 0.3782546\ttotal: 18m 28s\tremaining: 43m 5s\n","90:\tlearn: 0.3779117\ttotal: 18m 43s\tremaining: 43m\n","91:\tlearn: 0.3777876\ttotal: 18m 56s\tremaining: 42m 49s\n","92:\tlearn: 0.3776021\ttotal: 19m 8s\tremaining: 42m 36s\n","93:\tlearn: 0.3774949\ttotal: 19m 23s\tremaining: 42m 29s\n","94:\tlearn: 0.3772586\ttotal: 19m 35s\tremaining: 42m 16s\n","95:\tlearn: 0.3770986\ttotal: 19m 49s\tremaining: 42m 6s\n","96:\tlearn: 0.3770438\ttotal: 20m 1s\tremaining: 41m 54s\n","97:\tlearn: 0.3768338\ttotal: 20m 16s\tremaining: 41m 46s\n","98:\tlearn: 0.3767474\ttotal: 20m 25s\tremaining: 41m 29s\n","99:\tlearn: 0.3765993\ttotal: 20m 40s\tremaining: 41m 21s\n","100:\tlearn: 0.3765441\ttotal: 20m 52s\tremaining: 41m 8s\n","101:\tlearn: 0.3763957\ttotal: 21m 3s\tremaining: 40m 51s\n","102:\tlearn: 0.3762553\ttotal: 21m 16s\tremaining: 40m 41s\n","103:\tlearn: 0.3761965\ttotal: 21m 27s\tremaining: 40m 27s\n","104:\tlearn: 0.3761605\ttotal: 21m 37s\tremaining: 40m 10s\n","105:\tlearn: 0.3759566\ttotal: 21m 54s\tremaining: 40m 5s\n","106:\tlearn: 0.3756760\ttotal: 22m 8s\tremaining: 39m 56s\n","107:\tlearn: 0.3753264\ttotal: 22m 24s\tremaining: 39m 49s\n","108:\tlearn: 0.3750956\ttotal: 22m 36s\tremaining: 39m 36s\n","109:\tlearn: 0.3749870\ttotal: 22m 47s\tremaining: 39m 21s\n","110:\tlearn: 0.3748512\ttotal: 22m 59s\tremaining: 39m 8s\n","111:\tlearn: 0.3747635\ttotal: 23m 9s\tremaining: 38m 51s\n","112:\tlearn: 0.3745824\ttotal: 23m 24s\tremaining: 38m 44s\n","113:\tlearn: 0.3744806\ttotal: 23m 33s\tremaining: 38m 26s\n","114:\tlearn: 0.3744514\ttotal: 23m 44s\tremaining: 38m 11s\n","115:\tlearn: 0.3742305\ttotal: 23m 56s\tremaining: 37m 59s\n","116:\tlearn: 0.3741456\ttotal: 24m 11s\tremaining: 37m 50s\n","117:\tlearn: 0.3739799\ttotal: 24m 22s\tremaining: 37m 35s\n","118:\tlearn: 0.3738430\ttotal: 24m 33s\tremaining: 37m 21s\n","119:\tlearn: 0.3736746\ttotal: 24m 45s\tremaining: 37m 8s\n","120:\tlearn: 0.3735531\ttotal: 24m 56s\tremaining: 36m 54s\n","121:\tlearn: 0.3734424\ttotal: 25m 11s\tremaining: 36m 45s\n","122:\tlearn: 0.3733231\ttotal: 25m 23s\tremaining: 36m 31s\n","123:\tlearn: 0.3731801\ttotal: 25m 34s\tremaining: 36m 18s\n","124:\tlearn: 0.3729062\ttotal: 25m 47s\tremaining: 36m 6s\n","125:\tlearn: 0.3727460\ttotal: 25m 59s\tremaining: 35m 53s\n","126:\tlearn: 0.3726146\ttotal: 26m 13s\tremaining: 35m 43s\n","127:\tlearn: 0.3725395\ttotal: 26m 26s\tremaining: 35m 32s\n","128:\tlearn: 0.3724786\ttotal: 26m 39s\tremaining: 35m 20s\n","129:\tlearn: 0.3724009\ttotal: 26m 52s\tremaining: 35m 8s\n","130:\tlearn: 0.3724006\ttotal: 26m 55s\tremaining: 34m 43s\n","131:\tlearn: 0.3723530\ttotal: 27m 8s\tremaining: 34m 32s\n","132:\tlearn: 0.3720943\ttotal: 27m 20s\tremaining: 34m 19s\n","133:\tlearn: 0.3719545\ttotal: 27m 32s\tremaining: 34m 6s\n","134:\tlearn: 0.3717899\ttotal: 27m 44s\tremaining: 33m 54s\n","135:\tlearn: 0.3716650\ttotal: 27m 56s\tremaining: 33m 41s\n","136:\tlearn: 0.3712933\ttotal: 28m 9s\tremaining: 33m 30s\n","137:\tlearn: 0.3711155\ttotal: 28m 24s\tremaining: 33m 21s\n","138:\tlearn: 0.3710316\ttotal: 28m 35s\tremaining: 33m 6s\n","139:\tlearn: 0.3709672\ttotal: 28m 48s\tremaining: 32m 55s\n","140:\tlearn: 0.3709020\ttotal: 28m 58s\tremaining: 32m 40s\n","141:\tlearn: 0.3708207\ttotal: 29m 9s\tremaining: 32m 26s\n","142:\tlearn: 0.3707493\ttotal: 29m 20s\tremaining: 32m 13s\n","143:\tlearn: 0.3706651\ttotal: 29m 32s\tremaining: 31m 59s\n","144:\tlearn: 0.3704834\ttotal: 29m 45s\tremaining: 31m 48s\n","145:\tlearn: 0.3702946\ttotal: 30m 1s\tremaining: 31m 40s\n","146:\tlearn: 0.3701812\ttotal: 30m 14s\tremaining: 31m 28s\n","147:\tlearn: 0.3699138\ttotal: 30m 28s\tremaining: 31m 18s\n","148:\tlearn: 0.3698448\ttotal: 30m 39s\tremaining: 31m 4s\n","149:\tlearn: 0.3694991\ttotal: 30m 59s\tremaining: 30m 59s\n","150:\tlearn: 0.3692979\ttotal: 31m 10s\tremaining: 30m 45s\n","151:\tlearn: 0.3691402\ttotal: 31m 23s\tremaining: 30m 33s\n","152:\tlearn: 0.3689218\ttotal: 31m 37s\tremaining: 30m 23s\n","153:\tlearn: 0.3687851\ttotal: 31m 57s\tremaining: 30m 17s\n","154:\tlearn: 0.3687502\ttotal: 32m 8s\tremaining: 30m 3s\n","155:\tlearn: 0.3686350\ttotal: 32m 20s\tremaining: 29m 51s\n","156:\tlearn: 0.3684715\ttotal: 32m 33s\tremaining: 29m 39s\n","157:\tlearn: 0.3683317\ttotal: 32m 45s\tremaining: 29m 26s\n","158:\tlearn: 0.3681514\ttotal: 32m 59s\tremaining: 29m 15s\n","159:\tlearn: 0.3680995\ttotal: 33m 10s\tremaining: 29m 1s\n","160:\tlearn: 0.3679526\ttotal: 33m 24s\tremaining: 28m 50s\n","161:\tlearn: 0.3677048\ttotal: 33m 43s\tremaining: 28m 43s\n","162:\tlearn: 0.3675608\ttotal: 33m 56s\tremaining: 28m 31s\n","163:\tlearn: 0.3674401\ttotal: 34m 11s\tremaining: 28m 21s\n","164:\tlearn: 0.3673320\ttotal: 34m 23s\tremaining: 28m 8s\n","165:\tlearn: 0.3672130\ttotal: 34m 36s\tremaining: 27m 56s\n","166:\tlearn: 0.3671429\ttotal: 34m 49s\tremaining: 27m 44s\n","167:\tlearn: 0.3668743\ttotal: 35m 4s\tremaining: 27m 33s\n","168:\tlearn: 0.3666177\ttotal: 35m 17s\tremaining: 27m 21s\n","169:\tlearn: 0.3665544\ttotal: 35m 31s\tremaining: 27m 10s\n","170:\tlearn: 0.3663771\ttotal: 35m 43s\tremaining: 26m 56s\n","171:\tlearn: 0.3662994\ttotal: 35m 55s\tremaining: 26m 44s\n","172:\tlearn: 0.3661575\ttotal: 36m 5s\tremaining: 26m 29s\n","173:\tlearn: 0.3660451\ttotal: 36m 17s\tremaining: 26m 16s\n","174:\tlearn: 0.3659520\ttotal: 36m 28s\tremaining: 26m 3s\n","175:\tlearn: 0.3659178\ttotal: 36m 41s\tremaining: 25m 50s\n","176:\tlearn: 0.3657601\ttotal: 36m 53s\tremaining: 25m 38s\n","177:\tlearn: 0.3654267\ttotal: 37m 6s\tremaining: 25m 26s\n","178:\tlearn: 0.3652416\ttotal: 37m 18s\tremaining: 25m 12s\n","179:\tlearn: 0.3650231\ttotal: 37m 28s\tremaining: 24m 58s\n","180:\tlearn: 0.3648815\ttotal: 37m 41s\tremaining: 24m 46s\n","181:\tlearn: 0.3648430\ttotal: 37m 54s\tremaining: 24m 34s\n","182:\tlearn: 0.3646164\ttotal: 38m 7s\tremaining: 24m 22s\n","183:\tlearn: 0.3644760\ttotal: 38m 21s\tremaining: 24m 10s\n","184:\tlearn: 0.3643732\ttotal: 38m 35s\tremaining: 23m 59s\n","185:\tlearn: 0.3640958\ttotal: 38m 54s\tremaining: 23m 50s\n","186:\tlearn: 0.3639111\ttotal: 39m 8s\tremaining: 23m 39s\n","187:\tlearn: 0.3637653\ttotal: 39m 20s\tremaining: 23m 25s\n","188:\tlearn: 0.3637103\ttotal: 39m 33s\tremaining: 23m 14s\n","189:\tlearn: 0.3635663\ttotal: 39m 52s\tremaining: 23m 4s\n","190:\tlearn: 0.3632055\ttotal: 40m 11s\tremaining: 22m 55s\n","191:\tlearn: 0.3630923\ttotal: 40m 24s\tremaining: 22m 43s\n","192:\tlearn: 0.3628869\ttotal: 40m 40s\tremaining: 22m 32s\n","193:\tlearn: 0.3626591\ttotal: 40m 54s\tremaining: 22m 21s\n","194:\tlearn: 0.3624909\ttotal: 41m 9s\tremaining: 22m 9s\n","195:\tlearn: 0.3623363\ttotal: 41m 23s\tremaining: 21m 57s\n","196:\tlearn: 0.3620682\ttotal: 41m 36s\tremaining: 21m 45s\n","197:\tlearn: 0.3616664\ttotal: 41m 56s\tremaining: 21m 36s\n","198:\tlearn: 0.3614107\ttotal: 42m 8s\tremaining: 21m 23s\n","199:\tlearn: 0.3610510\ttotal: 42m 21s\tremaining: 21m 10s\n","200:\tlearn: 0.3609255\ttotal: 42m 34s\tremaining: 20m 58s\n","201:\tlearn: 0.3606975\ttotal: 42m 47s\tremaining: 20m 45s\n","202:\tlearn: 0.3604850\ttotal: 43m\tremaining: 20m 33s\n","203:\tlearn: 0.3604338\ttotal: 43m 15s\tremaining: 20m 21s\n","204:\tlearn: 0.3603299\ttotal: 43m 35s\tremaining: 20m 11s\n","205:\tlearn: 0.3600875\ttotal: 43m 51s\tremaining: 20m\n","206:\tlearn: 0.3600151\ttotal: 44m 3s\tremaining: 19m 47s\n","207:\tlearn: 0.3598796\ttotal: 44m 17s\tremaining: 19m 35s\n","208:\tlearn: 0.3596197\ttotal: 44m 30s\tremaining: 19m 22s\n","209:\tlearn: 0.3595412\ttotal: 44m 43s\tremaining: 19m 10s\n","210:\tlearn: 0.3594644\ttotal: 44m 55s\tremaining: 18m 57s\n","211:\tlearn: 0.3593612\ttotal: 45m 8s\tremaining: 18m 44s\n","212:\tlearn: 0.3593166\ttotal: 45m 20s\tremaining: 18m 31s\n","213:\tlearn: 0.3591603\ttotal: 45m 32s\tremaining: 18m 18s\n","214:\tlearn: 0.3590344\ttotal: 45m 45s\tremaining: 18m 5s\n","215:\tlearn: 0.3588212\ttotal: 46m 2s\tremaining: 17m 54s\n","216:\tlearn: 0.3586960\ttotal: 46m 17s\tremaining: 17m 42s\n","217:\tlearn: 0.3586566\ttotal: 46m 29s\tremaining: 17m 29s\n","218:\tlearn: 0.3585544\ttotal: 46m 45s\tremaining: 17m 17s\n","219:\tlearn: 0.3585122\ttotal: 46m 57s\tremaining: 17m 4s\n","220:\tlearn: 0.3584675\ttotal: 47m 15s\tremaining: 16m 53s\n","221:\tlearn: 0.3582968\ttotal: 47m 26s\tremaining: 16m 40s\n","222:\tlearn: 0.3580814\ttotal: 47m 39s\tremaining: 16m 27s\n","223:\tlearn: 0.3578943\ttotal: 47m 52s\tremaining: 16m 14s\n","224:\tlearn: 0.3577981\ttotal: 48m 8s\tremaining: 16m 2s\n","225:\tlearn: 0.3577184\ttotal: 48m 20s\tremaining: 15m 49s\n","226:\tlearn: 0.3576132\ttotal: 48m 36s\tremaining: 15m 37s\n","227:\tlearn: 0.3574919\ttotal: 48m 54s\tremaining: 15m 26s\n","228:\tlearn: 0.3572030\ttotal: 49m 6s\tremaining: 15m 13s\n","229:\tlearn: 0.3569243\ttotal: 49m 17s\tremaining: 15m\n","230:\tlearn: 0.3567597\ttotal: 49m 29s\tremaining: 14m 46s\n","231:\tlearn: 0.3566490\ttotal: 49m 41s\tremaining: 14m 33s\n","232:\tlearn: 0.3565727\ttotal: 49m 54s\tremaining: 14m 21s\n","233:\tlearn: 0.3564940\ttotal: 50m 10s\tremaining: 14m 9s\n","234:\tlearn: 0.3563698\ttotal: 50m 23s\tremaining: 13m 56s\n","235:\tlearn: 0.3563148\ttotal: 50m 39s\tremaining: 13m 44s\n","236:\tlearn: 0.3562552\ttotal: 50m 53s\tremaining: 13m 31s\n","237:\tlearn: 0.3560746\ttotal: 51m 6s\tremaining: 13m 18s\n","238:\tlearn: 0.3559253\ttotal: 51m 19s\tremaining: 13m 5s\n","239:\tlearn: 0.3558852\ttotal: 51m 30s\tremaining: 12m 52s\n","240:\tlearn: 0.3558561\ttotal: 51m 42s\tremaining: 12m 39s\n","241:\tlearn: 0.3557318\ttotal: 51m 57s\tremaining: 12m 27s\n","242:\tlearn: 0.3555682\ttotal: 52m 11s\tremaining: 12m 14s\n","243:\tlearn: 0.3554355\ttotal: 52m 26s\tremaining: 12m 2s\n","244:\tlearn: 0.3553329\ttotal: 52m 36s\tremaining: 11m 48s\n","245:\tlearn: 0.3551369\ttotal: 52m 48s\tremaining: 11m 35s\n","246:\tlearn: 0.3550172\ttotal: 52m 58s\tremaining: 11m 22s\n","247:\tlearn: 0.3549167\ttotal: 53m 14s\tremaining: 11m 9s\n","248:\tlearn: 0.3547290\ttotal: 53m 26s\tremaining: 10m 56s\n","249:\tlearn: 0.3545415\ttotal: 53m 41s\tremaining: 10m 44s\n","250:\tlearn: 0.3543019\ttotal: 53m 55s\tremaining: 10m 31s\n","251:\tlearn: 0.3541741\ttotal: 54m 6s\tremaining: 10m 18s\n","252:\tlearn: 0.3540217\ttotal: 54m 20s\tremaining: 10m 5s\n","253:\tlearn: 0.3540011\ttotal: 54m 32s\tremaining: 9m 52s\n","254:\tlearn: 0.3537736\ttotal: 54m 46s\tremaining: 9m 39s\n","255:\tlearn: 0.3536473\ttotal: 55m 2s\tremaining: 9m 27s\n","256:\tlearn: 0.3535403\ttotal: 55m 16s\tremaining: 9m 14s\n","257:\tlearn: 0.3534982\ttotal: 55m 31s\tremaining: 9m 2s\n","258:\tlearn: 0.3532999\ttotal: 55m 43s\tremaining: 8m 49s\n","259:\tlearn: 0.3530494\ttotal: 55m 55s\tremaining: 8m 36s\n","260:\tlearn: 0.3528872\ttotal: 56m 6s\tremaining: 8m 23s\n","261:\tlearn: 0.3526798\ttotal: 56m 18s\tremaining: 8m 10s\n","262:\tlearn: 0.3525762\ttotal: 56m 31s\tremaining: 7m 57s\n","263:\tlearn: 0.3525036\ttotal: 56m 41s\tremaining: 7m 43s\n","264:\tlearn: 0.3522974\ttotal: 56m 55s\tremaining: 7m 31s\n","265:\tlearn: 0.3520229\ttotal: 57m 13s\tremaining: 7m 18s\n","266:\tlearn: 0.3519241\ttotal: 57m 27s\tremaining: 7m 6s\n","267:\tlearn: 0.3516889\ttotal: 57m 39s\tremaining: 6m 53s\n","268:\tlearn: 0.3515263\ttotal: 57m 55s\tremaining: 6m 40s\n","269:\tlearn: 0.3512965\ttotal: 58m 9s\tremaining: 6m 27s\n","270:\tlearn: 0.3511084\ttotal: 58m 25s\tremaining: 6m 15s\n","271:\tlearn: 0.3509884\ttotal: 58m 39s\tremaining: 6m 2s\n","272:\tlearn: 0.3508324\ttotal: 58m 52s\tremaining: 5m 49s\n","273:\tlearn: 0.3506524\ttotal: 59m 6s\tremaining: 5m 36s\n","274:\tlearn: 0.3505374\ttotal: 59m 21s\tremaining: 5m 23s\n","275:\tlearn: 0.3504040\ttotal: 59m 35s\tremaining: 5m 10s\n","276:\tlearn: 0.3502456\ttotal: 59m 50s\tremaining: 4m 58s\n","277:\tlearn: 0.3501629\ttotal: 1h 1s\tremaining: 4m 44s\n","278:\tlearn: 0.3499770\ttotal: 1h 15s\tremaining: 4m 32s\n","279:\tlearn: 0.3498300\ttotal: 1h 28s\tremaining: 4m 19s\n","280:\tlearn: 0.3497346\ttotal: 1h 43s\tremaining: 4m 6s\n","281:\tlearn: 0.3497160\ttotal: 1h 55s\tremaining: 3m 53s\n","282:\tlearn: 0.3494674\ttotal: 1h 1m 12s\tremaining: 3m 40s\n","283:\tlearn: 0.3493618\ttotal: 1h 1m 26s\tremaining: 3m 27s\n","284:\tlearn: 0.3490645\ttotal: 1h 1m 43s\tremaining: 3m 14s\n","285:\tlearn: 0.3488240\ttotal: 1h 1m 57s\tremaining: 3m 1s\n","286:\tlearn: 0.3487638\ttotal: 1h 2m 12s\tremaining: 2m 49s\n","287:\tlearn: 0.3487092\ttotal: 1h 2m 25s\tremaining: 2m 36s\n","288:\tlearn: 0.3484791\ttotal: 1h 2m 37s\tremaining: 2m 23s\n","289:\tlearn: 0.3482728\ttotal: 1h 2m 53s\tremaining: 2m 10s\n","290:\tlearn: 0.3481254\ttotal: 1h 3m 5s\tremaining: 1m 57s\n","291:\tlearn: 0.3480306\ttotal: 1h 3m 21s\tremaining: 1m 44s\n","292:\tlearn: 0.3479358\ttotal: 1h 3m 32s\tremaining: 1m 31s\n","293:\tlearn: 0.3478741\ttotal: 1h 3m 45s\tremaining: 1m 18s\n","294:\tlearn: 0.3477621\ttotal: 1h 3m 58s\tremaining: 1m 5s\n","295:\tlearn: 0.3476915\ttotal: 1h 4m 12s\tremaining: 52.1s\n","296:\tlearn: 0.3475397\ttotal: 1h 4m 26s\tremaining: 39.1s\n","297:\tlearn: 0.3473971\ttotal: 1h 4m 40s\tremaining: 26s\n","298:\tlearn: 0.3472888\ttotal: 1h 4m 53s\tremaining: 13s\n","299:\tlearn: 0.3472257\ttotal: 1h 5m 4s\tremaining: 0us\n"]}],"source":["CBC = CatBoostClassifier(cat_features=columns,depth=15,learning_rate = 0.1, iterations = 300,one_hot_max_size=10)\n","CBC =CBC.fit(X_final_cat,y_cat)"]},{"cell_type":"markdown","metadata":{},"source":["## we conclude that CATBoost gives the best performance, so we use this model to predict all the test data"]},{"cell_type":"code","execution_count":119,"metadata":{},"outputs":[],"source":["testDF = pd.read_csv('ProjectTestData.csv')\n","testDF = testDF[['hour', 'C1', 'banner_pos', 'site_id', 'site_domain',\n","       'site_category', 'app_id', 'app_domain', 'app_category', 'device_id',\n","       'device_ip', 'device_model', 'device_type', 'device_conn_type', 'C14',\n","       'C15', 'C16', 'C17', 'C18', 'C19', 'C20', 'C21']]\n","test_cov = convert_hour(testDF)\n","testDF_cat[columns] = testDF_cov[columns].astype('category')\n","testDF_cat.columns = testDF_cat.columns.astype(str)"]},{"cell_type":"code","execution_count":126,"metadata":{},"outputs":[],"source":["testDF_cat = test_cov\n","testDF_cat[columns] = testDF_cat[columns].astype('category')\n","testDF_cat.columns = testDF_cat.columns.astype(str)"]},{"cell_type":"code","execution_count":127,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>hour</th>\n","      <th>C1</th>\n","      <th>banner_pos</th>\n","      <th>site_id</th>\n","      <th>site_domain</th>\n","      <th>site_category</th>\n","      <th>app_id</th>\n","      <th>app_domain</th>\n","      <th>app_category</th>\n","      <th>device_id</th>\n","      <th>device_ip</th>\n","      <th>device_model</th>\n","      <th>device_type</th>\n","      <th>device_conn_type</th>\n","      <th>C14</th>\n","      <th>C15</th>\n","      <th>C16</th>\n","      <th>C17</th>\n","      <th>C18</th>\n","      <th>C19</th>\n","      <th>C20</th>\n","      <th>C21</th>\n","      <th>weekday</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>9</td>\n","      <td>1005</td>\n","      <td>1</td>\n","      <td>85f751fd</td>\n","      <td>c4e18dd6</td>\n","      <td>50e219e0</td>\n","      <td>1dc72b4d</td>\n","      <td>2347f47a</td>\n","      <td>0f2161f8</td>\n","      <td>cd915ca3</td>\n","      <td>834cff24</td>\n","      <td>0d8ce284</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>8334</td>\n","      <td>300</td>\n","      <td>50</td>\n","      <td>761</td>\n","      <td>3</td>\n","      <td>175</td>\n","      <td>100075</td>\n","      <td>23</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>20</td>\n","      <td>1007</td>\n","      <td>0</td>\n","      <td>85f751fd</td>\n","      <td>c4e18dd6</td>\n","      <td>50e219e0</td>\n","      <td>8311368f</td>\n","      <td>1dc9b529</td>\n","      <td>0f2161f8</td>\n","      <td>ec0aff16</td>\n","      <td>6f6d6456</td>\n","      <td>6fe5a545</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>24303</td>\n","      <td>320</td>\n","      <td>50</td>\n","      <td>2788</td>\n","      <td>3</td>\n","      <td>295</td>\n","      <td>100194</td>\n","      <td>240</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>9</td>\n","      <td>1005</td>\n","      <td>0</td>\n","      <td>4e7614cf</td>\n","      <td>c1aa3c04</td>\n","      <td>f028772b</td>\n","      <td>ecad2386</td>\n","      <td>7801e8d9</td>\n","      <td>07d7df22</td>\n","      <td>a99f214a</td>\n","      <td>bd807c39</td>\n","      <td>a2f15940</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>24165</td>\n","      <td>320</td>\n","      <td>50</td>\n","      <td>2776</td>\n","      <td>0</td>\n","      <td>35</td>\n","      <td>-1</td>\n","      <td>79</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>1002</td>\n","      <td>0</td>\n","      <td>48c42b43</td>\n","      <td>de0f0f82</td>\n","      <td>50e219e0</td>\n","      <td>ecad2386</td>\n","      <td>7801e8d9</td>\n","      <td>07d7df22</td>\n","      <td>dfb9b781</td>\n","      <td>5ce9f91d</td>\n","      <td>a0215413</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>23438</td>\n","      <td>320</td>\n","      <td>50</td>\n","      <td>2684</td>\n","      <td>2</td>\n","      <td>1327</td>\n","      <td>-1</td>\n","      <td>52</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>19</td>\n","      <td>1005</td>\n","      <td>1</td>\n","      <td>e151e245</td>\n","      <td>7e091613</td>\n","      <td>f028772b</td>\n","      <td>ecad2386</td>\n","      <td>7801e8d9</td>\n","      <td>07d7df22</td>\n","      <td>a99f214a</td>\n","      <td>0da60c14</td>\n","      <td>5096d134</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>24084</td>\n","      <td>320</td>\n","      <td>50</td>\n","      <td>2761</td>\n","      <td>2</td>\n","      <td>35</td>\n","      <td>100148</td>\n","      <td>13</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>13015336</th>\n","      <td>10</td>\n","      <td>1005</td>\n","      <td>0</td>\n","      <td>28616ed9</td>\n","      <td>3bcb0c02</td>\n","      <td>f66779e6</td>\n","      <td>ecad2386</td>\n","      <td>7801e8d9</td>\n","      <td>07d7df22</td>\n","      <td>a99f214a</td>\n","      <td>e873c589</td>\n","      <td>41971090</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>23866</td>\n","      <td>320</td>\n","      <td>50</td>\n","      <td>2736</td>\n","      <td>3</td>\n","      <td>33</td>\n","      <td>100170</td>\n","      <td>246</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>13015337</th>\n","      <td>8</td>\n","      <td>1005</td>\n","      <td>1</td>\n","      <td>e151e245</td>\n","      <td>7e091613</td>\n","      <td>f028772b</td>\n","      <td>ecad2386</td>\n","      <td>7801e8d9</td>\n","      <td>07d7df22</td>\n","      <td>a99f214a</td>\n","      <td>61de248f</td>\n","      <td>779d90c2</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>23725</td>\n","      <td>320</td>\n","      <td>50</td>\n","      <td>2716</td>\n","      <td>3</td>\n","      <td>47</td>\n","      <td>-1</td>\n","      <td>23</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>13015338</th>\n","      <td>23</td>\n","      <td>1005</td>\n","      <td>0</td>\n","      <td>17d1b03f</td>\n","      <td>f3845767</td>\n","      <td>f028772b</td>\n","      <td>ecad2386</td>\n","      <td>7801e8d9</td>\n","      <td>07d7df22</td>\n","      <td>a99f214a</td>\n","      <td>a05ff870</td>\n","      <td>4ea23a13</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>22104</td>\n","      <td>320</td>\n","      <td>50</td>\n","      <td>2545</td>\n","      <td>0</td>\n","      <td>431</td>\n","      <td>-1</td>\n","      <td>221</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>13015339</th>\n","      <td>9</td>\n","      <td>1005</td>\n","      <td>0</td>\n","      <td>85f751fd</td>\n","      <td>c4e18dd6</td>\n","      <td>50e219e0</td>\n","      <td>ce183bbd</td>\n","      <td>ae637522</td>\n","      <td>cef3e649</td>\n","      <td>a99f214a</td>\n","      <td>24917551</td>\n","      <td>36b67a2a</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>24132</td>\n","      <td>320</td>\n","      <td>50</td>\n","      <td>2768</td>\n","      <td>1</td>\n","      <td>167</td>\n","      <td>100192</td>\n","      <td>71</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>13015340</th>\n","      <td>15</td>\n","      <td>1005</td>\n","      <td>1</td>\n","      <td>856e6d3f</td>\n","      <td>58a89a43</td>\n","      <td>f028772b</td>\n","      <td>ecad2386</td>\n","      <td>7801e8d9</td>\n","      <td>07d7df22</td>\n","      <td>a99f214a</td>\n","      <td>42544ac7</td>\n","      <td>ecb851b2</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>22680</td>\n","      <td>320</td>\n","      <td>50</td>\n","      <td>2528</td>\n","      <td>0</td>\n","      <td>167</td>\n","      <td>100075</td>\n","      <td>221</td>\n","      <td>4</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>13015341 rows × 23 columns</p>\n","</div>"],"text/plain":["          hour    C1 banner_pos   site_id site_domain site_category    app_id  \\\n","0            9  1005          1  85f751fd    c4e18dd6      50e219e0  1dc72b4d   \n","1           20  1007          0  85f751fd    c4e18dd6      50e219e0  8311368f   \n","2            9  1005          0  4e7614cf    c1aa3c04      f028772b  ecad2386   \n","3            1  1002          0  48c42b43    de0f0f82      50e219e0  ecad2386   \n","4           19  1005          1  e151e245    7e091613      f028772b  ecad2386   \n","...        ...   ...        ...       ...         ...           ...       ...   \n","13015336    10  1005          0  28616ed9    3bcb0c02      f66779e6  ecad2386   \n","13015337     8  1005          1  e151e245    7e091613      f028772b  ecad2386   \n","13015338    23  1005          0  17d1b03f    f3845767      f028772b  ecad2386   \n","13015339     9  1005          0  85f751fd    c4e18dd6      50e219e0  ce183bbd   \n","13015340    15  1005          1  856e6d3f    58a89a43      f028772b  ecad2386   \n","\n","         app_domain app_category device_id device_ip device_model device_type  \\\n","0          2347f47a     0f2161f8  cd915ca3  834cff24     0d8ce284           1   \n","1          1dc9b529     0f2161f8  ec0aff16  6f6d6456     6fe5a545           1   \n","2          7801e8d9     07d7df22  a99f214a  bd807c39     a2f15940           1   \n","3          7801e8d9     07d7df22  dfb9b781  5ce9f91d     a0215413           0   \n","4          7801e8d9     07d7df22  a99f214a  0da60c14     5096d134           1   \n","...             ...          ...       ...       ...          ...         ...   \n","13015336   7801e8d9     07d7df22  a99f214a  e873c589     41971090           1   \n","13015337   7801e8d9     07d7df22  a99f214a  61de248f     779d90c2           1   \n","13015338   7801e8d9     07d7df22  a99f214a  a05ff870     4ea23a13           1   \n","13015339   ae637522     cef3e649  a99f214a  24917551     36b67a2a           1   \n","13015340   7801e8d9     07d7df22  a99f214a  42544ac7     ecb851b2           1   \n","\n","         device_conn_type    C14  C15 C16   C17 C18   C19     C20  C21  \\\n","0                       0   8334  300  50   761   3   175  100075   23   \n","1                       2  24303  320  50  2788   3   295  100194  240   \n","2                       0  24165  320  50  2776   0    35      -1   79   \n","3                       0  23438  320  50  2684   2  1327      -1   52   \n","4                       0  24084  320  50  2761   2    35  100148   13   \n","...                   ...    ...  ...  ..   ...  ..   ...     ...  ...   \n","13015336                0  23866  320  50  2736   3    33  100170  246   \n","13015337                0  23725  320  50  2716   3    47      -1   23   \n","13015338                0  22104  320  50  2545   0   431      -1  221   \n","13015339                0  24132  320  50  2768   1   167  100192   71   \n","13015340                0  22680  320  50  2528   0   167  100075  221   \n","\n","          weekday  \n","0               1  \n","1               4  \n","2               4  \n","3               4  \n","4               4  \n","...           ...  \n","13015336        3  \n","13015337        3  \n","13015338        4  \n","13015339        4  \n","13015340        4  \n","\n","[13015341 rows x 23 columns]"]},"execution_count":127,"metadata":{},"output_type":"execute_result"}],"source":["testDF_cat"]},{"cell_type":"code","execution_count":128,"metadata":{},"outputs":[],"source":["pred_test_cat = CBC.predict_proba(testDF_cat)[:,1]"]},{"cell_type":"markdown","metadata":{},"source":["# Submission"]},{"cell_type":"code","execution_count":130,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>P(click)</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>3295858251275419735</td>\n","      <td>0.5</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>12281702837842634283</td>\n","      <td>0.5</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>4638380339534007785</td>\n","      <td>0.5</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>17039804736879076347</td>\n","      <td>0.5</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5753064066292192109</td>\n","      <td>0.5</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>13015336</th>\n","      <td>13925888664291307582</td>\n","      <td>0.5</td>\n","    </tr>\n","    <tr>\n","      <th>13015337</th>\n","      <td>16609686573956964319</td>\n","      <td>0.5</td>\n","    </tr>\n","    <tr>\n","      <th>13015338</th>\n","      <td>4549134116722204000</td>\n","      <td>0.5</td>\n","    </tr>\n","    <tr>\n","      <th>13015339</th>\n","      <td>2114008866308662546</td>\n","      <td>0.5</td>\n","    </tr>\n","    <tr>\n","      <th>13015340</th>\n","      <td>7842936548778884133</td>\n","      <td>0.5</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>13015341 rows × 2 columns</p>\n","</div>"],"text/plain":["                            id  P(click)\n","0          3295858251275419735       0.5\n","1         12281702837842634283       0.5\n","2          4638380339534007785       0.5\n","3         17039804736879076347       0.5\n","4          5753064066292192109       0.5\n","...                        ...       ...\n","13015336  13925888664291307582       0.5\n","13015337  16609686573956964319       0.5\n","13015338   4549134116722204000       0.5\n","13015339   2114008866308662546       0.5\n","13015340   7842936548778884133       0.5\n","\n","[13015341 rows x 2 columns]"]},"execution_count":130,"metadata":{},"output_type":"execute_result"}],"source":["sub = pd.read_csv('ProjectSubmission-TeamX.csv')\n","sub"]},{"cell_type":"code","execution_count":134,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>P(click)</th>\n","    </tr>\n","    <tr>\n","      <th>id</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>3295858251275419735</th>\n","      <td>0.096083</td>\n","    </tr>\n","    <tr>\n","      <th>12281702837842634283</th>\n","      <td>0.195642</td>\n","    </tr>\n","    <tr>\n","      <th>4638380339534007785</th>\n","      <td>0.039631</td>\n","    </tr>\n","    <tr>\n","      <th>17039804736879076347</th>\n","      <td>0.069791</td>\n","    </tr>\n","    <tr>\n","      <th>5753064066292192109</th>\n","      <td>0.209716</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>13925888664291307582</th>\n","      <td>0.023431</td>\n","    </tr>\n","    <tr>\n","      <th>16609686573956964319</th>\n","      <td>0.320530</td>\n","    </tr>\n","    <tr>\n","      <th>4549134116722204000</th>\n","      <td>0.167040</td>\n","    </tr>\n","    <tr>\n","      <th>2114008866308662546</th>\n","      <td>0.022792</td>\n","    </tr>\n","    <tr>\n","      <th>7842936548778884133</th>\n","      <td>0.033704</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>13015341 rows × 1 columns</p>\n","</div>"],"text/plain":["                      P(click)\n","id                            \n","3295858251275419735   0.096083\n","12281702837842634283  0.195642\n","4638380339534007785   0.039631\n","17039804736879076347  0.069791\n","5753064066292192109   0.209716\n","...                        ...\n","13925888664291307582  0.023431\n","16609686573956964319  0.320530\n","4549134116722204000   0.167040\n","2114008866308662546   0.022792\n","7842936548778884133   0.033704\n","\n","[13015341 rows x 1 columns]"]},"execution_count":134,"metadata":{},"output_type":"execute_result"}],"source":["sub['P(click)'] = pred_test_cat\n","sub = sub.set_index('id')\n","sub"]},{"cell_type":"code","execution_count":135,"metadata":{},"outputs":[],"source":["sub.to_csv('ProjectSubmission-Team10.csv')"]}],"metadata":{"colab":{"provenance":[]},"interpreter":{"hash":"ad91d35ff1a6958dfd0524343e69cea370466e678bdf1b785cc3e528f2bc3208"},"kernelspec":{"display_name":"Python 3.8.13 64-bit ('base': conda)","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.13"},"vscode":{"interpreter":{"hash":"26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"}}},"nbformat":4,"nbformat_minor":0}
